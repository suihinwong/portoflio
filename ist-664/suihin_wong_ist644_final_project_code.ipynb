{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "# Final Project - Spam Email Data Classification\n",
    "\n",
    "##############################################################################################################\n",
    "# step 1\n",
    "\n",
    "############ import packages\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\Downloads\n",
      "C:\\Users\\Henry\\Desktop\\ischool\\ist_664\\EmailSpamCorpora\\corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Subject: dobmeos with hgh my energy level has gone up ! stukm\\nintroducing\\ndoctor - formulated\\nhgh\\nhuman growth hormone - also called hgh\\nis referred to in medical science as the master hormone . it is very plentiful\\nwhen we are young , but near the age of twenty - one our bodies begin to produce\\nless of it . by the time we are forty nearly everyone is deficient in hgh ,\\nand at eighty our production has normally diminished at least 90 - 95 % .\\nadvantages of hgh :\\n- increased muscle strength\\n- loss in body fat\\n- increased bone density\\n- lower blood pressure\\n- quickens wound healing\\n- reduces cellulite\\n- improved vision\\n- wrinkle disappearance\\n- increased skin thickness texture\\n- increased energy levels\\n- improved sleep and emotional stability\\n- improved memory and mental alertness\\n- increased sexual potency\\n- resistance to common illness\\n- strengthened heart muscle\\n- controlled cholesterol\\n- controlled mood swings\\n- new hair growth and color restore\\nread\\nmore at this website\\nunsubscribe\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ check os packge and its functions\n",
    "\n",
    "# os.getcwd return current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# os.chdir(path) change current working directory to the path\n",
    "os.chdir(r\"C:\\Users\\Henry\\Desktop\\ischool\\ist_664\\EmailSpamCorpora\\corpus\")\n",
    "\n",
    "\n",
    "# check result\n",
    "print(os.getcwd())\n",
    "\n",
    "# check list.dir function\n",
    "# provide all file under the directory and in the spam folder\n",
    "# print(os.listdir(\"./spam\"))\n",
    "\n",
    "# testing open function\n",
    "z = open('./spam/' + \"0006.2003-12-18.GP.spam.txt\", 'r', encoding = 'latin-1')\n",
    "z.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ define function to read Spam and normal emails\n",
    "\n",
    "# remove the input \"limit\" as it is not necessary\n",
    "hamtexts = []\n",
    "spamtexts = []\n",
    "email_doc_word = []\n",
    "email_doc_sent = []\n",
    "email_doc_df = []\n",
    "\n",
    "def processspamham(path):\n",
    "    for file in os.listdir(\"./spam\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # read each spam txt file and add it to spamtexts list\n",
    "            f = open(\"./spam/\" + file, 'r', encoding = 'latin-1')\n",
    "            spamtexts.append(f.read())\n",
    "            # good practice to close the file after reading it\n",
    "            f.close()\n",
    "    for file in os.listdir(\"./ham\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # read each text ham file and add it to hamtexts list\n",
    "            f = open(\"./ham/\" + file, 'r', encoding = 'latin-1')\n",
    "            hamtexts.append(f.read())\n",
    "            f.close()\n",
    "    \n",
    "    print(\"Number of spam files: \", len(spamtexts))\n",
    "    print(\"Number of ham files: \", len(hamtexts))\n",
    "    \n",
    "    # create word tokens\n",
    "    for spam in spamtexts:\n",
    "        tokens = nltk.word_tokenize(spam)\n",
    "        email_doc_word.append((tokens, 'spam'))\n",
    "    for ham in hamtexts:\n",
    "        tokens = nltk.word_tokenize(ham)\n",
    "        email_doc_word.append((tokens, 'ham'))\n",
    "    \n",
    "    # create sentence tokens\n",
    "    for spam in spamtexts:\n",
    "        tokens = nltk.sent_tokenize(spam)\n",
    "        email_doc_sent.append((tokens, 'spam'))\n",
    "    for ham in hamtexts:\n",
    "        tokens = nltk.sent_tokenize(ham)\n",
    "        email_doc_sent.append((tokens, 'ham'))\n",
    "        \n",
    "    # create a list of raw data\n",
    "    for spam in spamtexts:\n",
    "        email_doc_df.append((spam, 'spam'))\n",
    "    for ham in hamtexts:\n",
    "        email_doc_df.append((ham, 'ham'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam files:  1500\n",
      "Number of ham files:  3672\n"
     ]
    }
   ],
   "source": [
    "# run the processspamham function\n",
    "\n",
    "processspamham(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Subject', ':', 'dobmeos', 'with', 'hgh', 'my', 'energy', 'level', 'has', 'gone', 'up', '!', 'stukm', 'introducing', 'doctor', '-', 'formulated', 'hgh', 'human', 'growth', 'hormone', '-', 'also', 'called', 'hgh', 'is', 'referred', 'to', 'in', 'medical', 'science', 'as', 'the', 'master', 'hormone', '.', 'it', 'is', 'very', 'plentiful', 'when', 'we', 'are', 'young', ',', 'but', 'near', 'the', 'age', 'of', 'twenty', '-', 'one', 'our', 'bodies', 'begin', 'to', 'produce', 'less', 'of', 'it', '.', 'by', 'the', 'time', 'we', 'are', 'forty', 'nearly', 'everyone', 'is', 'deficient', 'in', 'hgh', ',', 'and', 'at', 'eighty', 'our', 'production', 'has', 'normally', 'diminished', 'at', 'least', '90', '-', '95', '%', '.', 'advantages', 'of', 'hgh', ':', '-', 'increased', 'muscle', 'strength', '-', 'loss', 'in', 'body', 'fat', '-', 'increased', 'bone', 'density', '-', 'lower', 'blood', 'pressure', '-', 'quickens', 'wound', 'healing', '-', 'reduces', 'cellulite', '-', 'improved', 'vision', '-', 'wrinkle', 'disappearance', '-', 'increased', 'skin', 'thickness', 'texture', '-', 'increased', 'energy', 'levels', '-', 'improved', 'sleep', 'and', 'emotional', 'stability', '-', 'improved', 'memory', 'and', 'mental', 'alertness', '-', 'increased', 'sexual', 'potency', '-', 'resistance', 'to', 'common', 'illness', '-', 'strengthened', 'heart', 'muscle', '-', 'controlled', 'cholesterol', '-', 'controlled', 'mood', 'swings', '-', 'new', 'hair', 'growth', 'and', 'color', 'restore', 'read', 'more', 'at', 'this', 'website', 'unsubscribe'], 'spam')]\n"
     ]
    }
   ],
   "source": [
    "# testing the output from the processspamham function \n",
    "#print(email_doc_sent[:1])\n",
    "print(email_doc_word[:1])\n",
    "\n",
    "# [53] spam email has URL and was tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############# Data exploration\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# bar chart to show how many examples in each category\n",
    "plt.bar('Spam', len(os.listdir('./spam')), color = 'pink')\n",
    "plt.bar('Ham', len(os.listdir('./ham')), color = 'grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5172.000000\n",
       "mean      1030.231439\n",
       "std       1505.268730\n",
       "min         10.000000\n",
       "25%        238.000000\n",
       "50%        529.000000\n",
       "75%       1214.250000\n",
       "max      31860.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the lenght of each email in the dataset\n",
    "df_very_raw = pd.DataFrame(email_doc_df, columns=[\"text\",\"label\"])\n",
    "\n",
    "df_very_raw['length'] = df_very_raw['text'].str.len()\n",
    "df_very_raw['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3550.5999999999985\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(df_very_raw['length'], 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4654.000000\n",
       "mean      809.142673\n",
       "std       753.734692\n",
       "min        86.000000\n",
       "25%       264.250000\n",
       "50%       529.000000\n",
       "75%      1111.750000\n",
       "max      3547.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_very_raw_05_95['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Henry\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'email length distribution 5 to 95 percentile')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# email length distribution histogram\n",
    "\n",
    "# all emails included\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.distplot(df_very_raw['length']).set_title('email length distribution')\n",
    "\n",
    "# set up 95% percentile& 5% percentile and remove extreme value to check distribution\n",
    "quantile_95 = df_very_raw['length'].quantile(0.95)\n",
    "quantile_05 = df_very_raw['length'].quantile(0.05)\n",
    "df_very_raw_95 = df_very_raw[df_very_raw['length'] < quantile_95]\n",
    "df_very_raw_05_95 = df_very_raw_95[df_very_raw_95['length']>quantile_05]\n",
    "\n",
    "# only the middle 90% of the data \n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.distplot(df_very_raw_05_95['length']).set_title('email length distribution 5 to 95 percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='length'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Whisker plot to compare the length of spam and hame email in terms of length\n",
    "plt.figure(figsize=(12.8,6))\n",
    "\n",
    "# set up color to match the bar chart\n",
    "boxcolor = {\"spam\": \"pink\", \"ham\":\"grey\"}\n",
    "\n",
    "sns.boxplot(data=df_very_raw_05_95, x='label', y='length', width=.5, palette = boxcolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Pre-processing data\n",
    "##### 1. lower casing\n",
    "##### 2. remove non-alphabetical \n",
    "##### 3. remove stop words\n",
    "##### 4. Stemming\n",
    "##### 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. lower casing all words\n",
    "##### 2. remove non-alphabetical words\n",
    "\n",
    "# lowercase all words in email_doc_word\n",
    "email_doc_word_lower = []\n",
    "\n",
    "# define the regexp pattern\n",
    "import re\n",
    "# ^[^a-z]+$ defines a word consists of all non-alphabetical words\n",
    "# e.g., @5#$2% wil be removed\n",
    "# but b3d wont be removed\n",
    "pattern = re.compile('^[^a-z]+$')\n",
    "\n",
    "for i in range(len(email_doc_word)):\n",
    "    word_list = []\n",
    "    word_list_lower = []\n",
    "    # item includes the list of words and the result (i.e., spam/ham)\n",
    "    item = ()\n",
    "    word_list = email_doc_word[i][0]\n",
    "    \n",
    "    for word in word_list:\n",
    "        # if a word does not match the pattern, turn word into lowercase, and add to word lower list\n",
    "        if not (pattern.match(word)):\n",
    "            word_list_lower.append(word.lower())\n",
    "    \n",
    "    # replace original list of words with list of the same words with all lowercase\n",
    "    item = (word_list_lower, email_doc_word[i][1])\n",
    "    email_doc_word_lower.append(item)\n",
    "\n",
    "# test to see if the lowercase for email_doc_word works\n",
    "#print(email_doc_word_lower[:1])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 3. remove stop words\n",
    "# nltk stopwords\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "# more stopwords based on top 50 freq words\n",
    "morestopwords = ['subject']\n",
    "\n",
    "# all stopwords used \n",
    "stopwords = nltkstopwords + morestopwords\n",
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ect', 13900)\n",
      "('hou', 7289)\n",
      "('enron', 6555)\n",
      "('com', 3710)\n",
      "('please', 3200)\n",
      "('gas', 3034)\n",
      "('deal', 2827)\n",
      "('meter', 2459)\n",
      "('cc', 2371)\n",
      "('pm', 2343)\n",
      "('hpl', 2318)\n",
      "('e', 1976)\n",
      "('daren', 1901)\n",
      "('thanks', 1898)\n",
      "('corp', 1776)\n",
      "('know', 1588)\n",
      "('need', 1480)\n",
      "('new', 1437)\n",
      "('may', 1383)\n",
      "('mmbtu', 1349)\n",
      "('j', 1336)\n",
      "('forwarded', 1297)\n",
      "('get', 1276)\n",
      "('http', 1235)\n",
      "('price', 1206)\n",
      "('see', 1200)\n",
      "('company', 1198)\n",
      "('let', 1160)\n",
      "('information', 1154)\n",
      "('farmer', 1141)\n",
      "('l', 1108)\n",
      "('attached', 1097)\n",
      "('would', 1078)\n",
      "('xls', 1020)\n",
      "('us', 1018)\n",
      "('day', 1007)\n",
      "('time', 994)\n",
      "('message', 966)\n",
      "('one', 935)\n",
      "('contract', 920)\n",
      "('th', 906)\n",
      "('volume', 900)\n",
      "('mail', 892)\n",
      "('robert', 886)\n",
      "('month', 878)\n",
      "('sitara', 861)\n",
      "('p', 848)\n",
      "('email', 833)\n",
      "('nom', 832)\n",
      "('texas', 827)\n"
     ]
    }
   ],
   "source": [
    "# remove all stop words from email_doc_word file\n",
    "email_doc_word_lower_stopped_freqcheck = []\n",
    "email_doc_word_lower_stopped = []\n",
    "for i in range(len(email_doc_word_lower)):\n",
    "    word_list = []\n",
    "    word_list_lower_stopped = []\n",
    "    \n",
    "    # item includes the list of words and the result (i.e., spam/ham)\n",
    "    item = ()\n",
    "    \n",
    "    word_list = email_doc_word_lower[i][0]\n",
    "    for word in word_list:\n",
    "        if not (word in stopwords):\n",
    "            email_doc_word_lower_stopped_freqcheck.append(word)\n",
    "            word_list_lower_stopped.append(word)\n",
    "    \n",
    "    item = (word_list_lower_stopped, email_doc_word_lower[i][1])\n",
    "    email_doc_word_lower_stopped.append(item)\n",
    "\n",
    "\n",
    "# testing how the stopwords covers all stop words we want to remove\n",
    "# if we see some words we need to remove, go back and update the stopwords list\n",
    "email_doc_words_freq = nltk.FreqDist(email_doc_word_lower_stopped_freqcheck)\n",
    "email_doc_words_freq_top50 = email_doc_words_freq.most_common(50)\n",
    "for item in email_doc_words_freq_top50:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. stemming\n",
    "# define the stemmer \n",
    "# use porter stemmer but have other options like LanchesterStemmer() or SnowballStemmer()\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "# all_word_list is to generate most freq word list to create bag of words feature\n",
    "all_word_list = []\n",
    "email_doc_word_lower_stopped_stemmed = []\n",
    "for i in range(len(email_doc_word_lower_stopped)):\n",
    "    word_list = []\n",
    "    word_list_lower_stopped_stemmed = []\n",
    "    \n",
    "    # item includes the list of words and the result (i.e., spam/ham)\n",
    "    item = ()\n",
    "    \n",
    "    word_list = email_doc_word_lower_stopped[i][0]\n",
    "    for word in word_list:\n",
    "        word_list_lower_stopped_stemmed.append(porter.stem(word))\n",
    "        # add all stemmed words from all emails to all_word_list  \n",
    "        all_word_list.append(porter.stem(word))\n",
    "    \n",
    "    item = (word_list_lower_stopped_stemmed, email_doc_word_lower_stopped[i][1])\n",
    "    email_doc_word_lower_stopped_stemmed.append(item)\n",
    "\n",
    "# test the result\n",
    "#email_doc_word_lower_stopped_stemmed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 5. Lemmatization\n",
    "# this is the alternate step of 4. stemming\n",
    "# tested and lemmatization outperforms stemming\n",
    "\n",
    "# define the lemmatizer\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# all_word_list is to generate most freq word list to create bag of words feature\n",
    "all_word_list_1 = []\n",
    "email_doc_word_lower_stopped_lemmatized = []\n",
    "for i in range(len(email_doc_word_lower_stopped)):\n",
    "    word_list = []\n",
    "    word_list_lower_stopped_lemmatized = []\n",
    "    \n",
    "    # item includes the list of words and the result (i.e., spam/ham)\n",
    "    item = ()\n",
    "    \n",
    "    word_list = email_doc_word_lower_stopped[i][0]\n",
    "    for word in word_list:\n",
    "        word_list_lower_stopped_lemmatized.append(lemmatizer.lemmatize(word))\n",
    "        # add all stemmed words from all emails to all_word_list  \n",
    "        all_word_list_1.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    item = (word_list_lower_stopped_lemmatized, email_doc_word_lower_stopped[i][1])\n",
    "    email_doc_word_lower_stopped_lemmatized.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# step 2 create features and use NaiveBayes\n",
    "##### bag of word features\n",
    "# bag of word feature for all words before stemming/lemmatization\n",
    "# bag of word feature for all words after stemming\n",
    "# bag of word feature for all words after lemmatization\n",
    "\n",
    "# all words from pre-processing step 3 (meaning they are before stemming/lemmatization)\n",
    "all_word_list_freq_raw = nltk.FreqDist(word_list_lower_stopped)\n",
    "all_word_list_freq_raw_top2000 = all_word_list_freq_raw.most_common(2000)\n",
    "\n",
    "# all_word_list from pre-processing step 4 stemming\n",
    "all_word_list_freq_stem = nltk.FreqDist(all_word_list)\n",
    "all_word_list_freq_stem_top2000 = all_word_list_freq_stem.most_common(2000)\n",
    "#for item in all_word_list_freq_top2000[:50]:\n",
    "#    print(item)\n",
    "\n",
    "# all_word_list_1 from pre-processing step 5 lemmatization\n",
    "all_word_list_freq_lemma = nltk.FreqDist(all_word_list_1)\n",
    "all_word_list_freq_lemma_top2000 = all_word_list_freq_lemma.most_common(2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "\n",
    "# to check if a word before stemming/lemmatization is in the top 2000 freq word list\n",
    "top2000_word_raw = [word for (word, freq) in all_word_list_freq_raw_top2000]\n",
    "\n",
    "# to check if a stemmed word is in the top 2000 freq stemmed word list\n",
    "top2000_word_stem = [word for (word, freq) in all_word_list_freq_stem_top2000]\n",
    "\n",
    "# to check if a lemmatized word is in the top 2000 freq lemmatized word list\n",
    "top2000_word_lemma = [word for (word, freq) in all_word_list_freq_lemma_top2000]\n",
    "\n",
    "\n",
    "# function to check if each word in a email is in the top 2000 freq word list\n",
    "def bag_of_word(document, word_feature):\n",
    "    document_word = set(document)\n",
    "    feature = {}\n",
    "    for word in word_feature:\n",
    "        feature['V_{}'.format(word)] = (word in document_word)\n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create featureset for \n",
    "# 1. all words before stemming/lemmatization\n",
    "# 2. all words after stemming \n",
    "# 3. all words after lemmatization \n",
    "\n",
    "# 1\n",
    "featureset_stem = [(bag_of_word(d, top2000_word_stem), c) for (d, c) in email_doc_word_lower_stopped_stemmed] \n",
    "# 2\n",
    "featureset_lemma = [(bag_of_word(d, top2000_word_lemma), c) for (d, c) in email_doc_word_lower_stopped_lemmatized] \n",
    "# 3\n",
    "featureset_raw = [(bag_of_word(d, top2000_word_raw), c) for (d, c) in email_doc_word_lower_stopped] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### set up cross validation\n",
    "##### calculate precision/recall, and F1\n",
    "def cross_validation(num_folds, word_feature):\n",
    "    subset_size = round(len(word_feature)/num_folds)\n",
    "    accuracy_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    F1_list = []\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        test_round = word_feature[i*subset_size:][:subset_size]\n",
    "        train_round = word_feature[:i*subset_size] + word_feature[(i+1)*subset_size:]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_round)\n",
    "        accuracy = nltk.classify.accuracy(classifier, test_round)\n",
    "        print(i, \": \", accuracy)\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "        # get labels of all testing data and their prediction based on model\n",
    "        goldlist = []\n",
    "        predictedlist = []\n",
    "        for (feature, label) in test_round:\n",
    "            goldlist.append(label)\n",
    "            predictedlist.append(classifier.classify(feature))\n",
    "            \n",
    "        \n",
    "        # calculate precision/recall/F1 score\n",
    "\n",
    "        TP = FP = FN = TN = 0\n",
    "        # enumerate turn a list into a list of tuple of (index, original list value)\n",
    "        # e.g., enumerate(['spam', 'ham']) -> [(1, 'spam'), (2, 'ham')] \n",
    "        for j, val in enumerate(goldlist):\n",
    "                if val == 'spam' and predictedlist[j] == 'spam': TP += 1\n",
    "                if val == 'spam' and predictedlist[j] == 'ham':  FN += 1\n",
    "                if val == 'ham' and predictedlist[j] == 'ham':   TN += 1\n",
    "                if val == 'ham' and predictedlist[j] == 'spam':  FP += 1\n",
    "        \n",
    "        # use try function to avoid extreme rare case where the testing set are only spam or ham, which lead to TP + FP being 0 and zero division error\n",
    "        try:    \n",
    "            precision = TP/(TP + FP)\n",
    "        except ZeroDivisionError:\n",
    "            precision = 0\n",
    "            print(i, \" round recall TP + FP = 0\")\n",
    "        try:\n",
    "            recall = TP/(TP + FN)\n",
    "        except ZeroDivisionError:\n",
    "            recall = 0\n",
    "            print(i, \" round precision TP + FN = 0\")\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        try:\n",
    "            F1_list.append(2*(recall*precision)/(recall + precision))\n",
    "        except ZeroDivisionError:\n",
    "            F1_list.append(0)\n",
    "    \n",
    "    print(\"Mean accuracy: \", sum(accuracy_list)/num_folds)\n",
    "    print(\"Mean precision\", sum(precision_list)/num_folds)\n",
    "    print(\"Mean recall\", sum(recall_list)/num_folds)\n",
    "    print(\"Mean F1 score\", sum(F1_list)/num_folds)\n",
    "    \n",
    "    print('\\tPrecision\\tRecall\\t\\tF1')\n",
    "    for i in range(num_folds):\n",
    "        print(i, \"\\t\", '{:10.3f}'.format(precision_list[i]), '{:10.3f}'.format(recall_list[i]), \"{:10.3f}\".format(F1_list[i]))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.9206963249516441\n",
      "1 :  0.9303675048355899\n",
      "2 :  0.9439071566731141\n",
      "3 :  0.9032882011605415\n",
      "4 :  0.9090909090909091\n",
      "5 :  0.9032882011605415\n",
      "6 :  0.9168278529980658\n",
      "7 :  0.9226305609284333\n",
      "8 :  0.9264990328820116\n",
      "9 :  0.9400386847195358\n",
      "Mean accuracy:  0.9216634429400387\n",
      "Mean precision 0.8565800870826461\n",
      "Mean recall 0.8761716635882479\n",
      "Mean F1 score 0.8660838635834315\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.831      0.874      0.852\n",
      "1 \t      0.850      0.928      0.888\n",
      "2 \t      0.910      0.891      0.900\n",
      "3 \t      0.812      0.824      0.818\n",
      "4 \t      0.845      0.851      0.848\n",
      "5 \t      0.827      0.859      0.843\n",
      "6 \t      0.861      0.877      0.869\n",
      "7 \t      0.862      0.884      0.873\n",
      "8 \t      0.879      0.879      0.879\n",
      "9 \t      0.890      0.896      0.893\n",
      "0 :  0.9381044487427466\n",
      "1 :  0.9323017408123792\n",
      "2 :  0.941972920696325\n",
      "3 :  0.9381044487427466\n",
      "4 :  0.9264990328820116\n",
      "5 :  0.9342359767891683\n",
      "6 :  0.9439071566731141\n",
      "7 :  0.9458413926499033\n",
      "8 :  0.9187620889748549\n",
      "9 :  0.9342359767891683\n",
      "Mean accuracy:  0.9353965183752416\n",
      "Mean precision 0.8664974353169319\n",
      "Mean recall 0.9199070733274686\n",
      "Mean F1 score 0.8919095648888383\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.866      0.934      0.899\n",
      "1 \t      0.864      0.924      0.893\n",
      "2 \t      0.883      0.919      0.901\n",
      "3 \t      0.858      0.939      0.897\n",
      "4 \t      0.854      0.890      0.872\n",
      "5 \t      0.832      0.966      0.894\n",
      "6 \t      0.885      0.926      0.905\n",
      "7 \t      0.917      0.893      0.905\n",
      "8 \t      0.819      0.910      0.862\n",
      "9 \t      0.887      0.898      0.892\n",
      "0 :  0.8355899419729207\n",
      "1 :  0.7949709864603481\n",
      "2 :  0.7911025145067698\n",
      "3 :  0.8007736943907157\n",
      "4 :  0.8239845261121856\n",
      "5 :  0.7833655705996132\n",
      "6 :  0.7872340425531915\n",
      "7 :  0.8278529980657641\n",
      "8 :  0.804642166344294\n",
      "9 :  0.8181818181818182\n",
      "Mean accuracy:  0.8067698259187622\n",
      "Mean precision 0.6083833246555679\n",
      "Mean recall 0.939942141760908\n",
      "Mean F1 score 0.7381209521458318\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.650      0.940      0.768\n",
      "1 \t      0.608      0.950      0.741\n",
      "2 \t      0.562      0.904      0.693\n",
      "3 \t      0.621      0.906      0.737\n",
      "4 \t      0.620      0.937      0.747\n",
      "5 \t      0.581      0.961      0.724\n",
      "6 \t      0.564      0.972      0.714\n",
      "7 \t      0.626      0.959      0.757\n",
      "8 \t      0.622      0.897      0.735\n",
      "9 \t      0.630      0.975      0.765\n"
     ]
    }
   ],
   "source": [
    "# randome shuffle the featureset before running the function\n",
    "random.shuffle(featureset_stem)\n",
    "random.shuffle(featureset_lemma)  \n",
    "random.shuffle(featureset_raw) \n",
    "\n",
    "# featureset here only includes bag of word feature\n",
    "cross_validation(10, featureset_stem)\n",
    "cross_validation(10, featureset_lemma)  \n",
    "cross_validation(10, featureset_raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# step 3 add extra features\n",
    "from nltk.collocations import *\n",
    "\n",
    "##### add bigram and trigram features (based on words after stemming/lemmatization)\n",
    "# set up short cut for bigram association measures\n",
    "bigram_measure = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measure = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('activity', 'settled'), ('armstrong', 'paid'), ('buy', 'portion'), ('calling', 'phone'), ('cc', 'olsen'), ('contact', 'brazos'), ('couple', 'meetings'), ('current', 'role'), ('daren', 'j'), ('determine', 'go')]\n",
      "[('calling', 'phone', 'rolled'), ('cc', 'olsen', 'michael'), ('couple', 'meetings', 'today'), ('current', 'role', 'agent'), ('determine', 'go', 'forward'), ('enron', 'ownership', 'plant'), ('james', 'armstrong', 'paid'), ('jan', 'transfer', 'funds'), ('know', 'enron', 'ownership'), ('meetings', 'today', 'sorry')]\n"
     ]
    }
   ],
   "source": [
    "# data before lemmatization or stemming\n",
    "finder_raw_bi = BigramCollocationFinder.from_words(word_list_lower_stopped)\n",
    "finder_raw_tri = TrigramCollocationFinder.from_words(word_list_lower_stopped)\n",
    "\n",
    "# use chi sq value to generate top 500 bi/tri grams\n",
    "bigram_feature_raw = finder_raw_bi.nbest(bigram_measure.chi_sq, 500)\n",
    "trigram_feature_raw = finder_raw_tri.nbest(trigram_measure.chi_sq, 500)\n",
    "\n",
    "print(bigram_feature_raw[:10])\n",
    "print(trigram_feature_raw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aabvmmq', 'erzegvr'), ('aaer', 'xchxa'), ('aaiab', 'withoutrescript'), ('aaigrcrb', 'ndkcmojv'), ('aaihmqv', 'klfjhldm'), ('aamlrg', 'ujuerkm'), ('aar', 'comingup'), ('aashqcsni', 'jtrgfoz'), ('abas', 'darer'), ('abeckley', 'executrain')]\n",
      "[('aabvmmq', 'erzegvr', 'kpxotv'), ('aaigrcrb', 'ndkcmojv', 'xhnausk'), ('aaihmqv', 'klfjhldm', 'cjzgiobtx'), ('aamlrg', 'ujuerkm', 'iqbko'), ('aashqcsni', 'jtrgfoz', 'igaga'), ('abfan', 'znrlt', 'swq'), ('abpzhnpd', 'vjjnwwoz', 'ktjmnbmrg'), ('abshm', 'uxqlsh', 'mnz'), ('abtyw', 'ifpyc', 'edvv'), ('abvcm', 'ifldaavbbr', 'qvrocok')]\n"
     ]
    }
   ],
   "source": [
    "# after stemming\n",
    "# 'all_word_list' includes all words after stemming\n",
    "finder_stem_bi = BigramCollocationFinder.from_words(all_word_list)\n",
    "finder_stem_tri = TrigramCollocationFinder.from_words(all_word_list)\n",
    "\n",
    "# use chi sq value to generate top 500 bi/tri grams\n",
    "bigram_feature_stem = finder_stem_bi.nbest(bigram_measure.chi_sq, 500)\n",
    "trigram_feature_stem = finder_stem_tri.nbest(trigram_measure.chi_sq, 500)\n",
    "\n",
    "print(bigram_feature_stem[:10])\n",
    "print(trigram_feature_stem[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aabvmmq', 'erzegvr'), ('aaer', 'xchxa'), ('aaiab', 'withoutrescript'), ('aaigrcrb', 'ndkcmojv'), ('aaihmqv', 'klfjhldm'), ('aamlrg', 'ujuerkm'), ('aar', 'comingup'), ('aashqcsni', 'jtrgfoz'), ('abas', 'darer'), ('abeckley', 'executrain')]\n",
      "[('aabvmmq', 'erzegvr', 'kpxotv'), ('aaigrcrb', 'ndkcmojv', 'xhnausk'), ('aaihmqv', 'klfjhldm', 'cjzgiobtx'), ('aamlrg', 'ujuerkm', 'iqbko'), ('aashqcsni', 'jtrgfoz', 'igaga'), ('abfan', 'znrlt', 'swq'), ('abpzhnpd', 'vjjnwwoz', 'ktjmnbmrg'), ('abshm', 'uxqlsh', 'mnz'), ('abtyw', 'ifpyc', 'edvv'), ('abvcm', 'ifldaavbbr', 'qvrocok')]\n"
     ]
    }
   ],
   "source": [
    "# after lemmatization\n",
    "# 'all_word_list_1' includes all words after lemmatization \n",
    "finder_lemma_bi = BigramCollocationFinder.from_words(all_word_list_1)\n",
    "finder_lemma_tri = TrigramCollocationFinder.from_words(all_word_list_1)\n",
    "\n",
    "# use chi sq value to generate top 500 bi/tri grams\n",
    "bigram_feature_lemma = finder_stem_bi.nbest(bigram_measure.chi_sq, 500)\n",
    "trigram_feature_lemma = finder_stem_tri.nbest(trigram_measure.chi_sq, 500)\n",
    "\n",
    "print(bigram_feature_lemma[:10])\n",
    "print(trigram_feature_lemma[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to have both bag of word feature and bigram feature in the same featureset\n",
    "def bag_of_word_bigram(document, word_feature, bigram_feature):\n",
    "    feature = {}    \n",
    "    \n",
    "    # bag of word feature\n",
    "    document_word = set(document)\n",
    "    for word in word_feature:\n",
    "        feature['V_{}'.format(word)] = (word in document_word)\n",
    "    \n",
    "    # bigram feature\n",
    "    document_bigram = nltk.bigrams(document)\n",
    "    for bigram in bigram_feature:\n",
    "        feature['B_{}_{}'.format(bigram[0], bigram[1])] = (bigram in document_bigram)\n",
    "    \n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# create featureset (includes both bag of words and bigram feature) for \n",
    "# 1. all words before stemming/lemmatization\n",
    "# 2. all words after stemming \n",
    "# 3. all words after lemmatization \n",
    "\n",
    "# 1\n",
    "featureset_bi_raw = [(bag_of_word_bigram(d, top2000_word_raw, bigram_feature_raw), c) for (d,c) in email_doc_word_lower_stopped]\n",
    "# 2\n",
    "featureset_bi_stem = [(bag_of_word_bigram(d, top2000_word_stem, bigram_feature_stem), c) for (d,c) in email_doc_word_lower_stopped_stemmed]\n",
    "# 3\n",
    "featureset_bi_lemma = [(bag_of_word_bigram(d, top2000_word_lemma, bigram_feature_lemma), c) for (d,c) in email_doc_word_lower_stopped_lemmatized]\n",
    "\n",
    "\n",
    "# test the result\n",
    "print(featureset_bi_stem[1][0]['B_aabvmmq_erzegvr'])\n",
    "print(featureset_bi_lemma[1][0]['B_aabvmmq_erzegvr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.9381044487427466\n",
      "1 :  0.9187620889748549\n",
      "2 :  0.9148936170212766\n",
      "3 :  0.9361702127659575\n",
      "4 :  0.9187620889748549\n",
      "5 :  0.9303675048355899\n",
      "6 :  0.9168278529980658\n",
      "7 :  0.9148936170212766\n",
      "8 :  0.8916827852998066\n",
      "9 :  0.9187620889748549\n",
      "Mean accuracy:  0.9199226305609285\n",
      "Mean precision 0.8547091988308209\n",
      "Mean recall 0.8738721595633383\n",
      "Mean F1 score 0.86386638657892\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.897      0.856      0.876\n",
      "1 \t      0.840      0.864      0.852\n",
      "2 \t      0.823      0.871      0.846\n",
      "3 \t      0.874      0.904      0.889\n",
      "4 \t      0.839      0.904      0.870\n",
      "5 \t      0.850      0.899      0.874\n",
      "6 \t      0.847      0.885      0.865\n",
      "7 \t      0.854      0.875      0.864\n",
      "8 \t      0.846      0.827      0.836\n",
      "9 \t      0.877      0.854      0.865\n",
      "0 :  0.9148936170212766\n",
      "1 :  0.9535783365570599\n",
      "2 :  0.9323017408123792\n",
      "3 :  0.9323017408123792\n",
      "4 :  0.941972920696325\n",
      "5 :  0.9458413926499033\n",
      "6 :  0.9226305609284333\n",
      "7 :  0.9458413926499033\n",
      "8 :  0.9090909090909091\n",
      "9 :  0.9497098646034816\n",
      "Mean accuracy:  0.934816247582205\n",
      "Mean precision 0.865444345715507\n",
      "Mean recall 0.9196941712090654\n",
      "Mean F1 score 0.8911506134369208\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.836      0.890      0.863\n",
      "1 \t      0.897      0.946      0.921\n",
      "2 \t      0.869      0.908      0.888\n",
      "3 \t      0.870      0.910      0.890\n",
      "4 \t      0.893      0.905      0.899\n",
      "5 \t      0.916      0.904      0.910\n",
      "6 \t      0.811      0.945      0.873\n",
      "7 \t      0.854      0.972      0.909\n",
      "8 \t      0.797      0.894      0.843\n",
      "9 \t      0.911      0.923      0.917\n",
      "0 :  0.8143133462282398\n",
      "1 :  0.8297872340425532\n",
      "2 :  0.8065764023210832\n",
      "3 :  0.8355899419729207\n",
      "4 :  0.7911025145067698\n",
      "5 :  0.8085106382978723\n",
      "6 :  0.7794970986460348\n",
      "7 :  0.7794970986460348\n",
      "8 :  0.8239845261121856\n",
      "9 :  0.8085106382978723\n",
      "Mean accuracy:  0.8077369439071566\n",
      "Mean precision 0.6081534385818257\n",
      "Mean recall 0.9394615733376609\n",
      "Mean F1 score 0.7380610471403602\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.579      0.914      0.709\n",
      "1 \t      0.660      0.951      0.779\n",
      "2 \t      0.580      0.941      0.718\n",
      "3 \t      0.658      0.969      0.784\n",
      "4 \t      0.608      0.938      0.738\n",
      "5 \t      0.618      0.955      0.751\n",
      "6 \t      0.562      0.894      0.690\n",
      "7 \t      0.562      0.923      0.698\n",
      "8 \t      0.636      0.948      0.761\n",
      "9 \t      0.619      0.962      0.753\n"
     ]
    }
   ],
   "source": [
    "# run cross validation function with the bigram featureset\n",
    "# random shuffle first to avoid precision/recall has division by zero error\n",
    "random.shuffle(featureset_bi_stem)\n",
    "random.shuffle(featureset_bi_lemma)\n",
    "random.shuffle(featureset_bi_raw)\n",
    "\n",
    "cross_validation(10, featureset_bi_stem)\n",
    "cross_validation(10, featureset_bi_lemma)\n",
    "cross_validation(10, featureset_bi_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trigram feature to 'bag_of_word_and_bigram' function\n",
    "def bag_of_word_bigram_trigram(document, word_feature, bigram_feature, trigram_feature):\n",
    "    feature = {}    \n",
    "    \n",
    "    # bag of word feature\n",
    "    document_word = set(document)\n",
    "    for word in word_feature:\n",
    "        feature['V_{}'.format(word)] = (word in document_word)\n",
    "    \n",
    "    # bigram feature\n",
    "    document_bigram = nltk.bigrams(document)\n",
    "    for bigram in bigram_feature:\n",
    "        feature['B_{}_{}'.format(bigram[0], bigram[1])] = (bigram in document_bigram)\n",
    "    \n",
    "    # trigram feature\n",
    "    document_trigram = nltk.trigrams(document)\n",
    "    for trigram in trigram_feature:\n",
    "        feature['T_{}_{}_{}'.format(trigram[0], trigram[1], trigram[2])] = (trigram in document_trigram)   \n",
    "    \n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# create featureset (includes bag of words, bigram, and trigram features) for \n",
    "# 1. all words before stemming/lemmatization\n",
    "# 2. all words after stemming \n",
    "# 3. all words after lemmatization \n",
    "\n",
    "# 1\n",
    "featureset_bi_tri_raw = [(bag_of_word_bigram_trigram(d, top2000_word_raw, bigram_feature_raw, trigram_feature_raw), c) for (d,c) in email_doc_word_lower_stopped]\n",
    "# 2\n",
    "featureset_bi_tri_stem = [(bag_of_word_bigram_trigram(d, top2000_word_stem, bigram_feature_stem, trigram_feature_stem), c) for (d,c) in email_doc_word_lower_stopped_stemmed]\n",
    "# 3\n",
    "featureset_bi_tri_lemma = [(bag_of_word_bigram_trigram(d, top2000_word_lemma, bigram_feature_lemma, trigram_feature_lemma), c) for (d,c) in email_doc_word_lower_stopped_lemmatized]\n",
    "\n",
    "\n",
    "# test the result\n",
    "print(featureset_bi_tri_stem[1][0]['T_aabvmmq_erzegvr_kpxotv'])\n",
    "print(featureset_bi_tri_lemma[1][0]['T_aabvmmq_erzegvr_kpxotv'])\n",
    "#print(featureset_bi_tri_raw[1][0]['T_aabvmmq_erzegvr_kpxotv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.7988394584139265\n",
      "1 :  0.8259187620889749\n",
      "2 :  0.8239845261121856\n",
      "3 :  0.8143133462282398\n",
      "4 :  0.8297872340425532\n",
      "5 :  0.8201160541586073\n",
      "6 :  0.781431334622824\n",
      "7 :  0.7911025145067698\n",
      "8 :  0.7872340425531915\n",
      "9 :  0.7969052224371374\n",
      "Mean accuracy:  0.8069632495164409\n",
      "Mean precision 0.607754319010527\n",
      "Mean recall 0.9394465678174407\n",
      "Mean F1 score 0.7378219496374526\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.571      0.919      0.705\n",
      "1 \t      0.635      0.961      0.764\n",
      "2 \t      0.620      0.951      0.751\n",
      "3 \t      0.605      0.937      0.735\n",
      "4 \t      0.615      0.978      0.756\n",
      "5 \t      0.653      0.946      0.773\n",
      "6 \t      0.567      0.910      0.699\n",
      "7 \t      0.620      0.923      0.742\n",
      "8 \t      0.616      0.935      0.743\n",
      "9 \t      0.575      0.935      0.712\n",
      "0 :  0.9264990328820116\n",
      "1 :  0.9148936170212766\n",
      "2 :  0.9284332688588007\n",
      "3 :  0.9264990328820116\n",
      "4 :  0.9284332688588007\n",
      "5 :  0.9187620889748549\n",
      "6 :  0.9110251450676983\n",
      "7 :  0.9303675048355899\n",
      "8 :  0.9148936170212766\n",
      "9 :  0.90715667311412\n",
      "Mean accuracy:  0.9206963249516441\n",
      "Mean precision 0.8555533986097098\n",
      "Mean recall 0.8755733343281445\n",
      "Mean F1 score 0.8647907098819715\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.898      0.837      0.866\n",
      "1 \t      0.892      0.851      0.871\n",
      "2 \t      0.877      0.858      0.867\n",
      "3 \t      0.851      0.897      0.873\n",
      "4 \t      0.861      0.911      0.885\n",
      "5 \t      0.824      0.894      0.857\n",
      "6 \t      0.806      0.905      0.853\n",
      "7 \t      0.881      0.881      0.881\n",
      "8 \t      0.841      0.864      0.852\n",
      "9 \t      0.826      0.859      0.842\n",
      "0 :  0.9381044487427466\n",
      "1 :  0.9245647969052224\n",
      "2 :  0.9458413926499033\n",
      "3 :  0.9516441005802708\n",
      "4 :  0.9361702127659575\n",
      "5 :  0.9342359767891683\n",
      "6 :  0.9284332688588007\n",
      "7 :  0.9613152804642167\n",
      "8 :  0.9400386847195358\n",
      "9 :  0.90715667311412\n",
      "Mean accuracy:  0.9367504835589943\n",
      "Mean precision 0.8690246100132967\n",
      "Mean recall 0.9193214831621658\n",
      "Mean F1 score 0.8932636534792036\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.859      0.956      0.905\n",
      "1 \t      0.844      0.897      0.870\n",
      "2 \t      0.886      0.942      0.913\n",
      "3 \t      0.893      0.937      0.915\n",
      "4 \t      0.899      0.904      0.901\n",
      "5 \t      0.841      0.936      0.886\n",
      "6 \t      0.848      0.891      0.869\n",
      "7 \t      0.919      0.945      0.932\n",
      "8 \t      0.882      0.932      0.906\n",
      "9 \t      0.819      0.853      0.836\n"
     ]
    }
   ],
   "source": [
    "# run cross validation function with the bi/trigram featureset\n",
    "# random shuffle before runt function to avoid recall/precision have divison by zero error\n",
    "\n",
    "random.shuffle(featureset_bi_tri_raw)\n",
    "random.shuffle(featureset_bi_tri_stem)\n",
    "random.shuffle(featureset_bi_tri_lemma)\n",
    "\n",
    "\n",
    "cross_validation(10, featureset_bi_tri_raw)\n",
    "cross_validation(10, featureset_bi_tri_stem)\n",
    "cross_validation(10, featureset_bi_tri_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# step 4 sklearn package with TFIDF features and MNB/SVM model\n",
    "\n",
    "\n",
    "# import sklearn package\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas data frame for word before lemmatized or stemmed\n",
    "df_raw = pd.DataFrame(email_doc_word_lower_stopped, columns=[\"text\",\"label\"])\n",
    "# convert list to str and join each word with space\n",
    "df_raw[\"text\"] = df_raw[\"text\"].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "\n",
    "# create pandas data frame for stemmed word.\n",
    "df_stemmed = pd.DataFrame(email_doc_word_lower_stopped_stemmed, columns=[\"text\",\"label\"])\n",
    "# convert list to str and join each word with space\n",
    "df_stemmed[\"text\"] = df_stemmed[\"text\"].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "\n",
    "# create pandas data frame for lemmatized word.\n",
    "df_lemmatized = pd.DataFrame(email_doc_word_lower_stopped_lemmatized, columns=[\"text\",\"label\"])\n",
    "# convert list to str and join each word with space\n",
    "df_lemmatized[\"text\"] = df_lemmatized[\"text\"].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from pandas data fram for label column and text column for data before lemmatized and stemmed\n",
    "y_raw=df_raw['label'].values\n",
    "X_raw=df_raw['text'].values\n",
    "\n",
    "# extract values from pandas data fram for label column and text column for lemmatized data\n",
    "y_lemma=df_lemmatized['label'].values\n",
    "X_lemma=df_lemmatized['text'].values\n",
    "\n",
    "# extract values from pandas data fram for label column and text column for stemmed data\n",
    "y_stem=df_stemmed['label'].values\n",
    "X_stem=df_stemmed['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# several commonly used vectorizer setting\n",
    "bitrigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1', use_idf=True, ngram_range=(1,3), min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172, 22807)\n",
      "(5172, 22565)\n",
      "(5172, 22565)\n"
     ]
    }
   ],
   "source": [
    "# vectorizer fit the X training data and generate tranfored dataset together\n",
    "# fit_transform calculate the μ（population avg） and σ (population SD) and normalize data by z transformation \n",
    "# transform use the previously calculated μ and σ from fit_transform and normalize a new patch of data\n",
    "\n",
    "# TFIDF featuersets for data before stemming/lemmatization\n",
    "tfidf_X_raw_vec = bitrigram_tfidf_vectorizer.fit_transform(X_raw)\n",
    "print(tfidf_X_raw_vec.shape)\n",
    "\n",
    "# TFIDF featuresets for data after lemmatization\n",
    "tfidf_X_lemma_vec = bitrigram_tfidf_vectorizer.fit_transform(X_lemma)\n",
    "print(tfidf_X_lemma_vec.shape)\n",
    "\n",
    "# TFIDF featuresets for data after stemming\n",
    "tfidf_X_stem_vec = bitrigram_tfidf_vectorizer.transform(X_stem)\n",
    "print(tfidf_X_stem_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cross validation with MNB model\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create MNB model\n",
    "tfidf_nb_clf_1= MultinomialNB()\n",
    "\n",
    "name = ['ham', 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9791    0.9687    0.9739      3672\n",
      "        spam     0.9253    0.9493    0.9372      1500\n",
      "\n",
      "    accuracy                         0.9631      5172\n",
      "   macro avg     0.9522    0.9590    0.9555      5172\n",
      "weighted avg     0.9635    0.9631    0.9632      5172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data before stemming/lemmatization and the model CV results with TFIDF features (uni, bi, trigrams)\n",
    "scores_raw = cross_val_predict(tfidf_nb_clf_1, tfidf_X_raw_vec, y_raw, cv=10)\n",
    "\n",
    "scores_raw_report = classification_report(y_raw, scores_raw, target_names = name, digits= 4)\n",
    "print(scores_raw_report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9575    0.9820    0.9696      3672\n",
      "        spam     0.9531    0.8933    0.9222      1500\n",
      "\n",
      "    accuracy                         0.9563      5172\n",
      "   macro avg     0.9553    0.9377    0.9459      5172\n",
      "weighted avg     0.9562    0.9563    0.9559      5172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data after stemming and the model CV results with TFIDF features (uni, bi, trigrams)\n",
    "scores_stem = cross_val_predict(tfidf_nb_clf_1, tfidf_X_stem_vec, y_stem, cv=10)\n",
    "\n",
    "scores_stem_report = classification_report(y_stem, scores_stem, target_names = name, digits= 4)\n",
    "print(scores_stem_report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9791    0.9706    0.9748      3672\n",
      "        spam     0.9295    0.9493    0.9393      1500\n",
      "\n",
      "    accuracy                         0.9644      5172\n",
      "   macro avg     0.9543    0.9600    0.9571      5172\n",
      "weighted avg     0.9647    0.9644    0.9645      5172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data after lemmatization and the model CV results with TFIDF features (uni, bi, trigrams)\n",
    "scores_lemma = cross_val_predict(tfidf_nb_clf_1, tfidf_X_lemma_vec, y_lemma, cv=10)\n",
    "\n",
    "scores_lemma_report = classification_report(y_lemma, scores_lemma, target_names = name, digits= 4)\n",
    "print(scores_lemma_report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cross validation with SVM model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing data\n",
    "# random_state: whether shuffle before split\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(tfidf_X_raw_vec, y_raw, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(tfidf_X_stem_vec, y_stem, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_lemma_train, X_lemma_test, y_lemma_train, y_lemma_test = train_test_split(tfidf_X_lemma_vec, y_lemma, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tuning parameters for SVM\n",
    "param_tuning = {\n",
    "    \"C\": [1, 2, 5, 10, 25, 50, 100],\n",
    "    \"kernel\": [\"poly\", \"rbf\", \"sigmoid\", \"linear\"]\n",
    "}\n",
    "\n",
    "# set up scoring rules\n",
    "# need to specify 'spam' as postiive value in confusion matrix\n",
    "scoring_rule = {\"accuracy\": make_scorer(accuracy_score),\n",
    "                \"precision\": make_scorer(precision_score, pos_label = 'spam'),\n",
    "               \"recall\": make_scorer(recall_score, pos_label = 'spam'),\n",
    "               \"f1_score\": make_scorer(f1_score, pos_label=\"spam\")}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n",
      "[CV 1/10] END C=1, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.636) precision: (test=1.000) recall: (test=0.467) total time=   5.3s\n",
      "[CV 2/10] END C=1, kernel=poly; accuracy: (test=0.816) f1_score: (test=0.537) precision: (test=1.000) recall: (test=0.367) total time=   5.3s\n",
      "[CV 3/10] END C=1, kernel=poly; accuracy: (test=0.841) f1_score: (test=0.616) precision: (test=1.000) recall: (test=0.445) total time=   5.2s\n",
      "[CV 4/10] END C=1, kernel=poly; accuracy: (test=0.821) f1_score: (test=0.549) precision: (test=1.000) recall: (test=0.378) total time=   5.1s\n",
      "[CV 5/10] END C=1, kernel=poly; accuracy: (test=0.841) f1_score: (test=0.621) precision: (test=0.982) recall: (test=0.454) total time=   5.2s\n",
      "[CV 6/10] END C=1, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.632) precision: (test=1.000) recall: (test=0.462) total time=   4.9s\n",
      "[CV 7/10] END C=1, kernel=poly; accuracy: (test=0.824) f1_score: (test=0.558) precision: (test=1.000) recall: (test=0.387) total time=   5.0s\n",
      "[CV 8/10] END C=1, kernel=poly; accuracy: (test=0.843) f1_score: (test=0.624) precision: (test=1.000) recall: (test=0.454) total time=   5.1s\n",
      "[CV 9/10] END C=1, kernel=poly; accuracy: (test=0.831) f1_score: (test=0.583) precision: (test=1.000) recall: (test=0.412) total time=   5.2s\n",
      "[CV 10/10] END C=1, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   5.3s\n",
      "[CV 1/10] END C=1, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   3.7s\n",
      "[CV 2/10] END C=1, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   3.7s\n",
      "[CV 3/10] END C=1, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   3.7s\n",
      "[CV 4/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   3.6s\n",
      "[CV 5/10] END C=1, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   3.6s\n",
      "[CV 6/10] END C=1, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.991) recall: (test=0.975) total time=   3.7s\n",
      "[CV 7/10] END C=1, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   3.6s\n",
      "[CV 8/10] END C=1, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   3.7s\n",
      "[CV 9/10] END C=1, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   3.6s\n",
      "[CV 10/10] END C=1, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   3.8s\n",
      "[CV 1/10] END C=1, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.4s\n",
      "[CV 2/10] END C=1, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 3/10] END C=1, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.4s\n",
      "[CV 4/10] END C=1, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.4s\n",
      "[CV 5/10] END C=1, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.3s\n",
      "[CV 6/10] END C=1, kernel=sigmoid; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   1.3s\n",
      "[CV 7/10] END C=1, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.3s\n",
      "[CV 8/10] END C=1, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.3s\n",
      "[CV 9/10] END C=1, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.4s\n",
      "[CV 10/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.4s\n",
      "[CV 1/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.7s\n",
      "[CV 2/10] END C=1, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 3/10] END C=1, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=1, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.5s\n",
      "[CV 5/10] END C=1, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=1, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.6s\n",
      "[CV 7/10] END C=1, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.6s\n",
      "[CV 8/10] END C=1, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.6s\n",
      "[CV 9/10] END C=1, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 10/10] END C=1, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   1.5s\n",
      "[CV 1/10] END C=2, kernel=poly; accuracy: (test=0.865) f1_score: (test=0.696) precision: (test=1.000) recall: (test=0.533) total time=   5.5s\n",
      "[CV 2/10] END C=2, kernel=poly; accuracy: (test=0.826) f1_score: (test=0.571) precision: (test=1.000) recall: (test=0.400) total time=   5.6s\n",
      "[CV 3/10] END C=2, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.8s\n",
      "[CV 4/10] END C=2, kernel=poly; accuracy: (test=0.826) f1_score: (test=0.566) precision: (test=1.000) recall: (test=0.395) total time=   5.9s\n",
      "[CV 5/10] END C=2, kernel=poly; accuracy: (test=0.853) f1_score: (test=0.659) precision: (test=0.983) recall: (test=0.496) total time=   5.5s\n",
      "[CV 6/10] END C=2, kernel=poly; accuracy: (test=0.848) f1_score: (test=0.640) precision: (test=1.000) recall: (test=0.471) total time=   5.4s\n",
      "[CV 7/10] END C=2, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   5.5s\n",
      "[CV 8/10] END C=2, kernel=poly; accuracy: (test=0.850) f1_score: (test=0.648) precision: (test=1.000) recall: (test=0.479) total time=   5.6s\n",
      "[CV 9/10] END C=2, kernel=poly; accuracy: (test=0.835) f1_score: (test=0.600) precision: (test=1.000) recall: (test=0.429) total time=   5.5s\n",
      "[CV 10/10] END C=2, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.670) precision: (test=1.000) recall: (test=0.504) total time=   5.6s\n",
      "[CV 1/10] END C=2, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   5.3s\n",
      "[CV 2/10] END C=2, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   3.8s\n",
      "[CV 3/10] END C=2, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   3.8s\n",
      "[CV 4/10] END C=2, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   3.7s\n",
      "[CV 5/10] END C=2, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   3.8s\n",
      "[CV 6/10] END C=2, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.2s\n",
      "[CV 7/10] END C=2, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   3.7s\n",
      "[CV 8/10] END C=2, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   3.7s\n",
      "[CV 9/10] END C=2, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   3.7s\n",
      "[CV 10/10] END C=2, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   3.7s\n",
      "[CV 1/10] END C=2, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   1.3s\n",
      "[CV 2/10] END C=2, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.2s\n",
      "[CV 3/10] END C=2, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.2s\n",
      "[CV 4/10] END C=2, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.2s\n",
      "[CV 5/10] END C=2, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=2, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.2s\n",
      "[CV 7/10] END C=2, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.991) recall: (test=0.966) total time=   1.2s\n",
      "[CV 8/10] END C=2, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.2s\n",
      "[CV 9/10] END C=2, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.3s\n",
      "[CV 10/10] END C=2, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.4s\n",
      "[CV 1/10] END C=2, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.6s\n",
      "[CV 2/10] END C=2, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 3/10] END C=2, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=2, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.6s\n",
      "[CV 5/10] END C=2, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=2, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.5s\n",
      "[CV 7/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.983) recall: (test=0.950) total time=   1.5s\n",
      "[CV 8/10] END C=2, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.5s\n",
      "[CV 9/10] END C=2, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.5s\n",
      "[CV 10/10] END C=2, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.5s\n",
      "[CV 1/10] END C=5, kernel=poly; accuracy: (test=0.870) f1_score: (test=0.710) precision: (test=1.000) recall: (test=0.550) total time=   5.6s\n",
      "[CV 2/10] END C=5, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.613) precision: (test=1.000) recall: (test=0.442) total time=   5.6s\n",
      "[CV 3/10] END C=5, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.7s\n",
      "[CV 4/10] END C=5, kernel=poly; accuracy: (test=0.833) f1_score: (test=0.592) precision: (test=1.000) recall: (test=0.420) total time=   5.7s\n",
      "[CV 5/10] END C=5, kernel=poly; accuracy: (test=0.855) f1_score: (test=0.667) precision: (test=0.984) recall: (test=0.504) total time=   5.8s\n",
      "[CV 6/10] END C=5, kernel=poly; accuracy: (test=0.850) f1_score: (test=0.648) precision: (test=1.000) recall: (test=0.479) total time=   5.7s\n",
      "[CV 7/10] END C=5, kernel=poly; accuracy: (test=0.843) f1_score: (test=0.624) precision: (test=1.000) recall: (test=0.454) total time=   5.7s\n",
      "[CV 8/10] END C=5, kernel=poly; accuracy: (test=0.850) f1_score: (test=0.648) precision: (test=1.000) recall: (test=0.479) total time=   5.9s\n",
      "[CV 9/10] END C=5, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   5.8s\n",
      "[CV 10/10] END C=5, kernel=poly; accuracy: (test=0.864) f1_score: (test=0.692) precision: (test=1.000) recall: (test=0.529) total time=   5.9s\n",
      "[CV 1/10] END C=5, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   4.2s\n",
      "[CV 2/10] END C=5, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.2s\n",
      "[CV 3/10] END C=5, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   4.2s\n",
      "[CV 4/10] END C=5, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.2s\n",
      "[CV 5/10] END C=5, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   4.2s\n",
      "[CV 6/10] END C=5, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.2s\n",
      "[CV 7/10] END C=5, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   4.2s\n",
      "[CV 8/10] END C=5, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.1s\n",
      "[CV 9/10] END C=5, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   4.1s\n",
      "[CV 10/10] END C=5, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   4.2s\n",
      "[CV 1/10] END C=5, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.936) recall: (test=0.975) total time=   1.4s\n",
      "[CV 2/10] END C=5, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.3s\n",
      "[CV 3/10] END C=5, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.2s\n",
      "[CV 4/10] END C=5, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.3s\n",
      "[CV 5/10] END C=5, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=5, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.991) recall: (test=0.975) total time=   1.2s\n",
      "[CV 7/10] END C=5, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.974) recall: (test=0.950) total time=   1.3s\n",
      "[CV 8/10] END C=5, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.3s\n",
      "[CV 9/10] END C=5, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.2s\n",
      "[CV 10/10] END C=5, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.3s\n",
      "[CV 1/10] END C=5, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.6s\n",
      "[CV 2/10] END C=5, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.6s\n",
      "[CV 3/10] END C=5, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.6s\n",
      "[CV 4/10] END C=5, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.6s\n",
      "[CV 5/10] END C=5, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=5, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.992) recall: (test=0.983) total time=   1.6s\n",
      "[CV 7/10] END C=5, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   1.6s\n",
      "[CV 8/10] END C=5, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.983) recall: (test=1.000) total time=   1.6s\n",
      "[CV 9/10] END C=5, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 10/10] END C=5, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=10, kernel=poly; accuracy: (test=0.874) f1_score: (test=0.723) precision: (test=1.000) recall: (test=0.567) total time=   5.8s\n",
      "[CV 2/10] END C=10, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.636) precision: (test=1.000) recall: (test=0.467) total time=   5.9s\n",
      "[CV 3/10] END C=10, kernel=poly; accuracy: (test=0.874) f1_score: (test=0.720) precision: (test=1.000) recall: (test=0.563) total time=   5.9s\n",
      "[CV 4/10] END C=10, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   5.8s\n",
      "[CV 5/10] END C=10, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.689) precision: (test=0.984) recall: (test=0.529) total time=   5.8s\n",
      "[CV 6/10] END C=10, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.8s\n",
      "[CV 7/10] END C=10, kernel=poly; accuracy: (test=0.867) f1_score: (test=0.699) precision: (test=1.000) recall: (test=0.538) total time=   5.8s\n",
      "[CV 8/10] END C=10, kernel=poly; accuracy: (test=0.855) f1_score: (test=0.663) precision: (test=1.000) recall: (test=0.496) total time=   5.9s\n",
      "[CV 9/10] END C=10, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   6.6s\n",
      "[CV 10/10] END C=10, kernel=poly; accuracy: (test=0.872) f1_score: (test=0.714) precision: (test=1.000) recall: (test=0.555) total time=   5.9s\n",
      "[CV 1/10] END C=10, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   4.2s\n",
      "[CV 2/10] END C=10, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.2s\n",
      "[CV 3/10] END C=10, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   4.1s\n",
      "[CV 4/10] END C=10, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.1s\n",
      "[CV 5/10] END C=10, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   4.1s\n",
      "[CV 6/10] END C=10, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.1s\n",
      "[CV 7/10] END C=10, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   4.1s\n",
      "[CV 8/10] END C=10, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.1s\n",
      "[CV 9/10] END C=10, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   4.2s\n",
      "[CV 10/10] END C=10, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   4.2s\n",
      "[CV 1/10] END C=10, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.929) recall: (test=0.975) total time=   1.2s\n",
      "[CV 2/10] END C=10, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.2s\n",
      "[CV 3/10] END C=10, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.2s\n",
      "[CV 4/10] END C=10, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.2s\n",
      "[CV 5/10] END C=10, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=10, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.991) recall: (test=0.975) total time=   1.2s\n",
      "[CV 7/10] END C=10, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.974) recall: (test=0.958) total time=   1.2s\n",
      "[CV 8/10] END C=10, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.3s\n",
      "[CV 9/10] END C=10, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.2s\n",
      "[CV 10/10] END C=10, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   1.3s\n",
      "[CV 1/10] END C=10, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.6s\n",
      "[CV 2/10] END C=10, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.6s\n",
      "[CV 3/10] END C=10, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=10, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.5s\n",
      "[CV 5/10] END C=10, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=10, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.5s\n",
      "[CV 7/10] END C=10, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=10, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.5s\n",
      "[CV 9/10] END C=10, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.5s\n",
      "[CV 10/10] END C=10, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.6s\n",
      "[CV 1/10] END C=25, kernel=poly; accuracy: (test=0.930) f1_score: (test=0.865) precision: (test=0.979) recall: (test=0.775) total time=   5.9s\n",
      "[CV 2/10] END C=25, kernel=poly; accuracy: (test=0.865) f1_score: (test=0.702) precision: (test=0.971) recall: (test=0.550) total time=   5.9s\n",
      "[CV 3/10] END C=25, kernel=poly; accuracy: (test=0.915) f1_score: (test=0.828) precision: (test=1.000) recall: (test=0.706) total time=   5.8s\n",
      "[CV 4/10] END C=25, kernel=poly; accuracy: (test=0.896) f1_score: (test=0.779) precision: (test=1.000) recall: (test=0.639) total time=   5.9s\n",
      "[CV 5/10] END C=25, kernel=poly; accuracy: (test=0.908) f1_score: (test=0.812) precision: (test=0.988) recall: (test=0.689) total time=   5.8s\n",
      "[CV 6/10] END C=25, kernel=poly; accuracy: (test=0.891) f1_score: (test=0.767) precision: (test=1.000) recall: (test=0.622) total time=   5.7s\n",
      "[CV 7/10] END C=25, kernel=poly; accuracy: (test=0.911) f1_score: (test=0.816) precision: (test=1.000) recall: (test=0.689) total time=   5.7s\n",
      "[CV 8/10] END C=25, kernel=poly; accuracy: (test=0.908) f1_score: (test=0.810) precision: (test=1.000) recall: (test=0.681) total time=   5.9s\n",
      "[CV 9/10] END C=25, kernel=poly; accuracy: (test=0.867) f1_score: (test=0.703) precision: (test=0.985) recall: (test=0.546) total time=   5.8s\n",
      "[CV 10/10] END C=25, kernel=poly; accuracy: (test=0.903) f1_score: (test=0.798) precision: (test=1.000) recall: (test=0.664) total time=   5.8s\n",
      "[CV 1/10] END C=25, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   4.1s\n",
      "[CV 2/10] END C=25, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.2s\n",
      "[CV 3/10] END C=25, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   4.1s\n",
      "[CV 4/10] END C=25, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.1s\n",
      "[CV 5/10] END C=25, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   4.1s\n",
      "[CV 6/10] END C=25, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.1s\n",
      "[CV 7/10] END C=25, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   4.1s\n",
      "[CV 8/10] END C=25, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.1s\n",
      "[CV 9/10] END C=25, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   4.2s\n",
      "[CV 10/10] END C=25, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   4.2s\n",
      "[CV 1/10] END C=25, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.2s\n",
      "[CV 2/10] END C=25, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.937) recall: (test=0.992) total time=   1.1s\n",
      "[CV 3/10] END C=25, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=25, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.1s\n",
      "[CV 5/10] END C=25, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=25, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.2s\n",
      "[CV 7/10] END C=25, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   1.2s\n",
      "[CV 8/10] END C=25, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.2s\n",
      "[CV 9/10] END C=25, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.2s\n",
      "[CV 10/10] END C=25, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.3s\n",
      "[CV 1/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.944) recall: (test=0.992) total time=   1.5s\n",
      "[CV 2/10] END C=25, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.935) recall: (test=0.967) total time=   1.5s\n",
      "[CV 3/10] END C=25, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.4s\n",
      "[CV 4/10] END C=25, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.5s\n",
      "[CV 5/10] END C=25, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.4s\n",
      "[CV 6/10] END C=25, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.5s\n",
      "[CV 9/10] END C=25, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.4s\n",
      "[CV 10/10] END C=25, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.5s\n",
      "[CV 1/10] END C=50, kernel=poly; accuracy: (test=0.894) f1_score: (test=0.845) precision: (test=0.732) recall: (test=1.000) total time=   5.8s\n",
      "[CV 2/10] END C=50, kernel=poly; accuracy: (test=0.947) f1_score: (test=0.904) precision: (test=0.954) recall: (test=0.858) total time=   5.8s\n",
      "[CV 3/10] END C=50, kernel=poly; accuracy: (test=0.920) f1_score: (test=0.878) precision: (test=0.783) recall: (test=1.000) total time=   5.7s\n",
      "[CV 4/10] END C=50, kernel=poly; accuracy: (test=0.906) f1_score: (test=0.859) precision: (test=0.753) recall: (test=1.000) total time=   5.7s\n",
      "[CV 5/10] END C=50, kernel=poly; accuracy: (test=0.947) f1_score: (test=0.915) precision: (test=0.849) recall: (test=0.992) total time=   5.8s\n",
      "[CV 6/10] END C=50, kernel=poly; accuracy: (test=0.940) f1_score: (test=0.905) precision: (test=0.826) recall: (test=1.000) total time=   5.7s\n",
      "[CV 7/10] END C=50, kernel=poly; accuracy: (test=0.901) f1_score: (test=0.852) precision: (test=0.747) recall: (test=0.992) total time=   5.7s\n",
      "[CV 8/10] END C=50, kernel=poly; accuracy: (test=0.901) f1_score: (test=0.853) precision: (test=0.744) recall: (test=1.000) total time=   5.7s\n",
      "[CV 9/10] END C=50, kernel=poly; accuracy: (test=0.964) f1_score: (test=0.940) precision: (test=0.894) recall: (test=0.992) total time=   5.8s\n",
      "[CV 10/10] END C=50, kernel=poly; accuracy: (test=0.879) f1_score: (test=0.826) precision: (test=0.704) recall: (test=1.000) total time=   5.8s\n",
      "[CV 1/10] END C=50, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   4.1s\n",
      "[CV 2/10] END C=50, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.2s\n",
      "[CV 3/10] END C=50, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   4.2s\n",
      "[CV 4/10] END C=50, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.2s\n",
      "[CV 5/10] END C=50, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   4.1s\n",
      "[CV 6/10] END C=50, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.1s\n",
      "[CV 7/10] END C=50, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   4.2s\n",
      "[CV 8/10] END C=50, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.1s\n",
      "[CV 9/10] END C=50, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   4.1s\n",
      "[CV 10/10] END C=50, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   4.1s\n",
      "[CV 1/10] END C=50, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.2s\n",
      "[CV 2/10] END C=50, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.937) recall: (test=0.992) total time=   1.1s\n",
      "[CV 3/10] END C=50, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=50, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.1s\n",
      "[CV 5/10] END C=50, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=50, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.1s\n",
      "[CV 7/10] END C=50, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   1.1s\n",
      "[CV 8/10] END C=50, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.2s\n",
      "[CV 9/10] END C=50, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.1s\n",
      "[CV 10/10] END C=50, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.1s\n",
      "[CV 1/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.944) recall: (test=0.992) total time=   1.4s\n",
      "[CV 2/10] END C=50, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.935) recall: (test=0.967) total time=   1.4s\n",
      "[CV 3/10] END C=50, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.4s\n",
      "[CV 4/10] END C=50, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.4s\n",
      "[CV 5/10] END C=50, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.4s\n",
      "[CV 6/10] END C=50, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.4s\n",
      "[CV 9/10] END C=50, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.4s\n",
      "[CV 10/10] END C=50, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.4s\n",
      "[CV 1/10] END C=100, kernel=poly; accuracy: (test=0.749) f1_score: (test=0.698) precision: (test=0.536) recall: (test=1.000) total time=   5.8s\n",
      "[CV 2/10] END C=100, kernel=poly; accuracy: (test=0.824) f1_score: (test=0.767) precision: (test=0.622) recall: (test=1.000) total time=   5.9s\n",
      "[CV 3/10] END C=100, kernel=poly; accuracy: (test=0.739) f1_score: (test=0.688) precision: (test=0.524) recall: (test=1.000) total time=   5.9s\n",
      "[CV 4/10] END C=100, kernel=poly; accuracy: (test=0.749) f1_score: (test=0.696) precision: (test=0.534) recall: (test=1.000) total time=   6.0s\n",
      "[CV 5/10] END C=100, kernel=poly; accuracy: (test=0.790) f1_score: (test=0.732) precision: (test=0.578) recall: (test=1.000) total time=   5.9s\n",
      "[CV 6/10] END C=100, kernel=poly; accuracy: (test=0.804) f1_score: (test=0.746) precision: (test=0.595) recall: (test=1.000) total time=   5.8s\n",
      "[CV 7/10] END C=100, kernel=poly; accuracy: (test=0.756) f1_score: (test=0.702) precision: (test=0.541) recall: (test=1.000) total time=   6.6s\n",
      "[CV 8/10] END C=100, kernel=poly; accuracy: (test=0.782) f1_score: (test=0.726) precision: (test=0.569) recall: (test=1.000) total time=   6.7s\n",
      "[CV 9/10] END C=100, kernel=poly; accuracy: (test=0.785) f1_score: (test=0.728) precision: (test=0.572) recall: (test=1.000) total time=   5.9s\n",
      "[CV 10/10] END C=100, kernel=poly; accuracy: (test=0.746) f1_score: (test=0.694) precision: (test=0.531) recall: (test=1.000) total time=   5.8s\n",
      "[CV 1/10] END C=100, kernel=rbf; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   4.2s\n",
      "[CV 2/10] END C=100, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 3/10] END C=100, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   4.2s\n",
      "[CV 4/10] END C=100, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.2s\n",
      "[CV 5/10] END C=100, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   4.2s\n",
      "[CV 6/10] END C=100, kernel=rbf; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=1.000) recall: (test=0.975) total time=   4.2s\n",
      "[CV 7/10] END C=100, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=1.000) recall: (test=0.958) total time=   4.2s\n",
      "[CV 8/10] END C=100, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.1s\n",
      "[CV 9/10] END C=100, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   4.2s\n",
      "[CV 10/10] END C=100, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   4.1s\n",
      "[CV 1/10] END C=100, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.2s\n",
      "[CV 2/10] END C=100, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.937) recall: (test=0.992) total time=   1.1s\n",
      "[CV 3/10] END C=100, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=100, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.2s\n",
      "[CV 5/10] END C=100, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.2s\n",
      "[CV 6/10] END C=100, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.1s\n",
      "[CV 7/10] END C=100, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   1.2s\n",
      "[CV 8/10] END C=100, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.2s\n",
      "[CV 9/10] END C=100, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.1s\n",
      "[CV 10/10] END C=100, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.2s\n",
      "[CV 1/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.944) recall: (test=0.992) total time=   1.4s\n",
      "[CV 2/10] END C=100, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.935) recall: (test=0.967) total time=   1.4s\n",
      "[CV 3/10] END C=100, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.4s\n",
      "[CV 4/10] END C=100, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.4s\n",
      "[CV 5/10] END C=100, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=100, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.4s\n",
      "[CV 9/10] END C=100, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.4s\n",
      "[CV 10/10] END C=100, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.4s\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9945    0.9904    0.9924       727\n",
      "        spam     0.9775    0.9870    0.9822       308\n",
      "\n",
      "    accuracy                         0.9894      1035\n",
      "   macro avg     0.9860    0.9887    0.9873      1035\n",
      "weighted avg     0.9894    0.9894    0.9894      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gridsearch Linear SVM with raw data\n",
    "\n",
    "# when using more than 1 score to decide best model, need to specify which score to be used for \"refit\" \n",
    "grid_raw = GridSearchCV(SVC(), param_tuning, refit = 'f1_score', verbose = 3,  scoring = scoring_rule, cv = 10) \n",
    "\n",
    "# grid search with training data set\n",
    "grid_raw.fit(X_raw_train, y_raw_train)\n",
    "# print the best parameter\n",
    "print(grid_raw.best_params_)\n",
    "\n",
    "# predicting the testing dataset\n",
    "grid_raw_pred = grid_raw.predict(X_raw_test)\n",
    "# print prediction result\n",
    "print(classification_report(y_raw_test, grid_raw_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n",
      "[CV 1/10] END C=1, kernel=poly; accuracy: (test=0.911) f1_score: (test=0.821) precision: (test=0.977) recall: (test=0.708) total time=   3.6s\n",
      "[CV 2/10] END C=1, kernel=poly; accuracy: (test=0.872) f1_score: (test=0.725) precision: (test=0.959) recall: (test=0.583) total time=   4.2s\n",
      "[CV 3/10] END C=1, kernel=poly; accuracy: (test=0.908) f1_score: (test=0.810) precision: (test=1.000) recall: (test=0.681) total time=   3.6s\n",
      "[CV 4/10] END C=1, kernel=poly; accuracy: (test=0.870) f1_score: (test=0.707) precision: (test=1.000) recall: (test=0.546) total time=   3.7s\n",
      "[CV 5/10] END C=1, kernel=poly; accuracy: (test=0.899) f1_score: (test=0.788) precision: (test=0.987) recall: (test=0.655) total time=   3.6s\n",
      "[CV 6/10] END C=1, kernel=poly; accuracy: (test=0.906) f1_score: (test=0.804) precision: (test=1.000) recall: (test=0.672) total time=   3.6s\n",
      "[CV 7/10] END C=1, kernel=poly; accuracy: (test=0.896) f1_score: (test=0.779) precision: (test=1.000) recall: (test=0.639) total time=   3.7s\n",
      "[CV 8/10] END C=1, kernel=poly; accuracy: (test=0.886) f1_score: (test=0.754) precision: (test=1.000) recall: (test=0.605) total time=   4.2s\n",
      "[CV 9/10] END C=1, kernel=poly; accuracy: (test=0.872) f1_score: (test=0.717) precision: (test=0.985) recall: (test=0.563) total time=   3.6s\n",
      "[CV 10/10] END C=1, kernel=poly; accuracy: (test=0.886) f1_score: (test=0.754) precision: (test=1.000) recall: (test=0.605) total time=   3.6s\n",
      "[CV 1/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 3/10] END C=1, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   1.6s\n",
      "[CV 4/10] END C=1, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=1, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=1, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=1, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 8/10] END C=1, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.6s\n",
      "[CV 9/10] END C=1, kernel=rbf; accuracy: (test=0.966) f1_score: (test=0.942) precision: (test=0.934) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.7s\n",
      "[CV 1/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   0.8s\n",
      "[CV 2/10] END C=1, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   0.8s\n",
      "[CV 3/10] END C=1, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   0.8s\n",
      "[CV 4/10] END C=1, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.8s\n",
      "[CV 5/10] END C=1, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   0.8s\n",
      "[CV 6/10] END C=1, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   0.9s\n",
      "[CV 7/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   0.8s\n",
      "[CV 8/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   0.8s\n",
      "[CV 9/10] END C=1, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   0.8s\n",
      "[CV 10/10] END C=1, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.8s\n",
      "[CV 1/10] END C=1, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.960) recall: (test=0.992) total time=   0.8s\n",
      "[CV 2/10] END C=1, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   0.8s\n",
      "[CV 3/10] END C=1, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   0.8s\n",
      "[CV 4/10] END C=1, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.8s\n",
      "[CV 5/10] END C=1, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   0.8s\n",
      "[CV 6/10] END C=1, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.983) recall: (test=1.000) total time=   0.8s\n",
      "[CV 7/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   0.8s\n",
      "[CV 8/10] END C=1, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   0.8s\n",
      "[CV 9/10] END C=1, kernel=linear; accuracy: (test=0.966) f1_score: (test=0.941) precision: (test=0.941) recall: (test=0.941) total time=   0.8s\n",
      "[CV 10/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   0.8s\n",
      "[CV 1/10] END C=2, kernel=poly; accuracy: (test=0.913) f1_score: (test=0.827) precision: (test=0.977) recall: (test=0.717) total time=   4.3s\n",
      "[CV 2/10] END C=2, kernel=poly; accuracy: (test=0.882) f1_score: (test=0.751) precision: (test=0.961) recall: (test=0.617) total time=   3.6s\n",
      "[CV 3/10] END C=2, kernel=poly; accuracy: (test=0.911) f1_score: (test=0.816) precision: (test=1.000) recall: (test=0.689) total time=   3.6s\n",
      "[CV 4/10] END C=2, kernel=poly; accuracy: (test=0.877) f1_score: (test=0.733) precision: (test=0.972) recall: (test=0.588) total time=   3.6s\n",
      "[CV 5/10] END C=2, kernel=poly; accuracy: (test=0.903) f1_score: (test=0.802) precision: (test=0.976) recall: (test=0.681) total time=   3.7s\n",
      "[CV 6/10] END C=2, kernel=poly; accuracy: (test=0.915) f1_score: (test=0.828) precision: (test=1.000) recall: (test=0.706) total time=   3.7s\n",
      "[CV 7/10] END C=2, kernel=poly; accuracy: (test=0.903) f1_score: (test=0.798) precision: (test=1.000) recall: (test=0.664) total time=   3.6s\n",
      "[CV 8/10] END C=2, kernel=poly; accuracy: (test=0.896) f1_score: (test=0.779) precision: (test=1.000) recall: (test=0.639) total time=   4.5s\n",
      "[CV 9/10] END C=2, kernel=poly; accuracy: (test=0.877) f1_score: (test=0.733) precision: (test=0.972) recall: (test=0.588) total time=   3.7s\n",
      "[CV 10/10] END C=2, kernel=poly; accuracy: (test=0.906) f1_score: (test=0.804) precision: (test=1.000) recall: (test=0.672) total time=   3.7s\n",
      "[CV 1/10] END C=2, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=2, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.7s\n",
      "[CV 3/10] END C=2, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 4/10] END C=2, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.7s\n",
      "[CV 5/10] END C=2, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.7s\n",
      "[CV 6/10] END C=2, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.7s\n",
      "[CV 7/10] END C=2, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=2, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.7s\n",
      "[CV 9/10] END C=2, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=2, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.7s\n",
      "[CV 1/10] END C=2, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=2, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.937) recall: (test=0.983) total time=   0.7s\n",
      "[CV 3/10] END C=2, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   0.7s\n",
      "[CV 4/10] END C=2, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   0.7s\n",
      "[CV 5/10] END C=2, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.929) recall: (test=0.983) total time=   0.7s\n",
      "[CV 6/10] END C=2, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   0.7s\n",
      "[CV 7/10] END C=2, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.966) recall: (test=0.958) total time=   0.7s\n",
      "[CV 8/10] END C=2, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   0.7s\n",
      "[CV 9/10] END C=2, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.945) precision: (test=0.949) recall: (test=0.941) total time=   0.7s\n",
      "[CV 10/10] END C=2, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.7s\n",
      "[CV 1/10] END C=2, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.960) recall: (test=0.992) total time=   0.8s\n",
      "[CV 2/10] END C=2, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.8s\n",
      "[CV 3/10] END C=2, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   0.8s\n",
      "[CV 4/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.8s\n",
      "[CV 5/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   0.8s\n",
      "[CV 6/10] END C=2, kernel=linear; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   0.7s\n",
      "[CV 7/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.8s\n",
      "[CV 8/10] END C=2, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   0.8s\n",
      "[CV 9/10] END C=2, kernel=linear; accuracy: (test=0.973) f1_score: (test=0.953) precision: (test=0.966) recall: (test=0.941) total time=   0.8s\n",
      "[CV 10/10] END C=2, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.8s\n",
      "[CV 1/10] END C=5, kernel=poly; accuracy: (test=0.935) f1_score: (test=0.876) precision: (test=0.979) recall: (test=0.792) total time=   4.3s\n",
      "[CV 2/10] END C=5, kernel=poly; accuracy: (test=0.894) f1_score: (test=0.782) precision: (test=0.963) recall: (test=0.658) total time=   3.6s\n",
      "[CV 3/10] END C=5, kernel=poly; accuracy: (test=0.923) f1_score: (test=0.845) precision: (test=1.000) recall: (test=0.731) total time=   3.6s\n",
      "[CV 4/10] END C=5, kernel=poly; accuracy: (test=0.896) f1_score: (test=0.784) precision: (test=0.975) recall: (test=0.655) total time=   3.6s\n",
      "[CV 5/10] END C=5, kernel=poly; accuracy: (test=0.913) f1_score: (test=0.825) precision: (test=0.977) recall: (test=0.714) total time=   3.6s\n",
      "[CV 6/10] END C=5, kernel=poly; accuracy: (test=0.923) f1_score: (test=0.845) precision: (test=1.000) recall: (test=0.731) total time=   3.7s\n",
      "[CV 7/10] END C=5, kernel=poly; accuracy: (test=0.911) f1_score: (test=0.816) precision: (test=1.000) recall: (test=0.689) total time=   3.7s\n",
      "[CV 8/10] END C=5, kernel=poly; accuracy: (test=0.915) f1_score: (test=0.829) precision: (test=0.988) recall: (test=0.714) total time=   3.7s\n",
      "[CV 9/10] END C=5, kernel=poly; accuracy: (test=0.889) f1_score: (test=0.768) precision: (test=0.962) recall: (test=0.639) total time=   3.7s\n",
      "[CV 10/10] END C=5, kernel=poly; accuracy: (test=0.920) f1_score: (test=0.839) precision: (test=1.000) recall: (test=0.723) total time=   3.7s\n",
      "[CV 1/10] END C=5, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.7s\n",
      "[CV 2/10] END C=5, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.7s\n",
      "[CV 3/10] END C=5, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 4/10] END C=5, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=5, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=5, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=5, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=5, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.6s\n",
      "[CV 9/10] END C=5, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=5, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=5, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.947) precision: (test=0.935) recall: (test=0.958) total time=   0.6s\n",
      "[CV 2/10] END C=5, kernel=sigmoid; accuracy: (test=0.966) f1_score: (test=0.942) precision: (test=0.942) recall: (test=0.942) total time=   0.6s\n",
      "[CV 3/10] END C=5, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   0.6s\n",
      "[CV 4/10] END C=5, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.954) precision: (test=0.950) recall: (test=0.958) total time=   0.6s\n",
      "[CV 5/10] END C=5, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.929) recall: (test=0.983) total time=   0.6s\n",
      "[CV 6/10] END C=5, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   0.6s\n",
      "[CV 7/10] END C=5, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   0.6s\n",
      "[CV 8/10] END C=5, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   0.6s\n",
      "[CV 9/10] END C=5, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.953) precision: (test=0.966) recall: (test=0.941) total time=   0.6s\n",
      "[CV 10/10] END C=5, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.921) recall: (test=0.983) total time=   0.6s\n",
      "[CV 1/10] END C=5, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.937) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=5, kernel=linear; accuracy: (test=0.966) f1_score: (test=0.943) precision: (test=0.927) recall: (test=0.958) total time=   0.8s\n",
      "[CV 3/10] END C=5, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   0.8s\n",
      "[CV 4/10] END C=5, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.958) precision: (test=0.958) recall: (test=0.958) total time=   0.7s\n",
      "[CV 5/10] END C=5, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.929) recall: (test=0.992) total time=   0.7s\n",
      "[CV 6/10] END C=5, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   0.7s\n",
      "[CV 7/10] END C=5, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   0.7s\n",
      "[CV 8/10] END C=5, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   0.7s\n",
      "[CV 9/10] END C=5, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.7s\n",
      "[CV 10/10] END C=5, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   0.8s\n",
      "[CV 1/10] END C=10, kernel=poly; accuracy: (test=0.959) f1_score: (test=0.925) precision: (test=0.981) recall: (test=0.875) total time=   3.6s\n",
      "[CV 2/10] END C=10, kernel=poly; accuracy: (test=0.920) f1_score: (test=0.845) precision: (test=0.968) recall: (test=0.750) total time=   3.7s\n",
      "[CV 3/10] END C=10, kernel=poly; accuracy: (test=0.954) f1_score: (test=0.913) precision: (test=1.000) recall: (test=0.840) total time=   3.7s\n",
      "[CV 4/10] END C=10, kernel=poly; accuracy: (test=0.944) f1_score: (test=0.898) precision: (test=0.953) recall: (test=0.849) total time=   3.7s\n",
      "[CV 5/10] END C=10, kernel=poly; accuracy: (test=0.944) f1_score: (test=0.896) precision: (test=0.971) recall: (test=0.832) total time=   3.7s\n",
      "[CV 6/10] END C=10, kernel=poly; accuracy: (test=0.947) f1_score: (test=0.898) precision: (test=1.000) recall: (test=0.815) total time=   3.7s\n",
      "[CV 7/10] END C=10, kernel=poly; accuracy: (test=0.940) f1_score: (test=0.884) precision: (test=0.990) recall: (test=0.798) total time=   3.7s\n",
      "[CV 8/10] END C=10, kernel=poly; accuracy: (test=0.966) f1_score: (test=0.938) precision: (test=0.991) recall: (test=0.891) total time=   3.7s\n",
      "[CV 9/10] END C=10, kernel=poly; accuracy: (test=0.918) f1_score: (test=0.838) precision: (test=0.967) recall: (test=0.739) total time=   3.7s\n",
      "[CV 10/10] END C=10, kernel=poly; accuracy: (test=0.969) f1_score: (test=0.943) precision: (test=0.982) recall: (test=0.908) total time=   3.7s\n",
      "[CV 1/10] END C=10, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=10, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.6s\n",
      "[CV 3/10] END C=10, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.7s\n",
      "[CV 4/10] END C=10, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=10, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=10, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=10, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=10, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.6s\n",
      "[CV 9/10] END C=10, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=10, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=10, kernel=sigmoid; accuracy: (test=0.959) f1_score: (test=0.931) precision: (test=0.906) recall: (test=0.958) total time=   0.5s\n",
      "[CV 2/10] END C=10, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.943) recall: (test=0.958) total time=   0.5s\n",
      "[CV 3/10] END C=10, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   0.6s\n",
      "[CV 4/10] END C=10, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.954) precision: (test=0.943) recall: (test=0.966) total time=   0.5s\n",
      "[CV 5/10] END C=10, kernel=sigmoid; accuracy: (test=0.966) f1_score: (test=0.943) precision: (test=0.920) recall: (test=0.966) total time=   0.5s\n",
      "[CV 6/10] END C=10, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.6s\n",
      "[CV 7/10] END C=10, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.6s\n",
      "[CV 8/10] END C=10, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.6s\n",
      "[CV 9/10] END C=10, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.944) precision: (test=0.973) recall: (test=0.916) total time=   0.5s\n",
      "[CV 10/10] END C=10, kernel=sigmoid; accuracy: (test=0.961) f1_score: (test=0.935) precision: (test=0.906) recall: (test=0.966) total time=   0.6s\n",
      "[CV 1/10] END C=10, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=10, kernel=linear; accuracy: (test=0.966) f1_score: (test=0.943) precision: (test=0.927) recall: (test=0.958) total time=   0.7s\n",
      "[CV 3/10] END C=10, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.7s\n",
      "[CV 4/10] END C=10, kernel=linear; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.935) recall: (test=0.975) total time=   0.7s\n",
      "[CV 5/10] END C=10, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.915) recall: (test=0.992) total time=   0.7s\n",
      "[CV 6/10] END C=10, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.7s\n",
      "[CV 7/10] END C=10, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.7s\n",
      "[CV 8/10] END C=10, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.7s\n",
      "[CV 9/10] END C=10, kernel=linear; accuracy: (test=0.966) f1_score: (test=0.942) precision: (test=0.934) recall: (test=0.950) total time=   0.7s\n",
      "[CV 10/10] END C=10, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.951) precision: (test=0.921) recall: (test=0.983) total time=   0.7s\n",
      "[CV 1/10] END C=25, kernel=poly; accuracy: (test=0.949) f1_score: (test=0.919) precision: (test=0.856) recall: (test=0.992) total time=   3.5s\n",
      "[CV 2/10] END C=25, kernel=poly; accuracy: (test=0.964) f1_score: (test=0.939) precision: (test=0.913) recall: (test=0.967) total time=   3.6s\n",
      "[CV 3/10] END C=25, kernel=poly; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.915) recall: (test=0.992) total time=   3.6s\n",
      "[CV 4/10] END C=25, kernel=poly; accuracy: (test=0.942) f1_score: (test=0.908) precision: (test=0.837) recall: (test=0.992) total time=   3.5s\n",
      "[CV 5/10] END C=25, kernel=poly; accuracy: (test=0.957) f1_score: (test=0.929) precision: (test=0.874) recall: (test=0.992) total time=   3.6s\n",
      "[CV 6/10] END C=25, kernel=poly; accuracy: (test=0.959) f1_score: (test=0.933) precision: (test=0.881) recall: (test=0.992) total time=   3.6s\n",
      "[CV 7/10] END C=25, kernel=poly; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.944) recall: (test=0.992) total time=   3.5s\n",
      "[CV 8/10] END C=25, kernel=poly; accuracy: (test=0.947) f1_score: (test=0.915) precision: (test=0.844) recall: (test=1.000) total time=   3.6s\n",
      "[CV 9/10] END C=25, kernel=poly; accuracy: (test=0.939) f1_score: (test=0.904) precision: (test=0.831) recall: (test=0.992) total time=   3.6s\n",
      "[CV 10/10] END C=25, kernel=poly; accuracy: (test=0.935) f1_score: (test=0.897) precision: (test=0.819) recall: (test=0.992) total time=   3.6s\n",
      "[CV 1/10] END C=25, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=25, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.6s\n",
      "[CV 3/10] END C=25, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 4/10] END C=25, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.7s\n",
      "[CV 5/10] END C=25, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.7s\n",
      "[CV 6/10] END C=25, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=25, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.7s\n",
      "[CV 8/10] END C=25, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.7s\n",
      "[CV 9/10] END C=25, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.7s\n",
      "[CV 10/10] END C=25, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.7s\n",
      "[CV 1/10] END C=25, kernel=sigmoid; accuracy: (test=0.961) f1_score: (test=0.935) precision: (test=0.913) recall: (test=0.958) total time=   0.5s\n",
      "[CV 2/10] END C=25, kernel=sigmoid; accuracy: (test=0.959) f1_score: (test=0.929) precision: (test=0.933) recall: (test=0.925) total time=   0.5s\n",
      "[CV 3/10] END C=25, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   0.5s\n",
      "[CV 4/10] END C=25, kernel=sigmoid; accuracy: (test=0.952) f1_score: (test=0.917) precision: (test=0.902) recall: (test=0.933) total time=   0.5s\n",
      "[CV 5/10] END C=25, kernel=sigmoid; accuracy: (test=0.961) f1_score: (test=0.934) precision: (test=0.919) recall: (test=0.950) total time=   0.5s\n",
      "[CV 6/10] END C=25, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.947) precision: (test=0.927) recall: (test=0.966) total time=   0.5s\n",
      "[CV 7/10] END C=25, kernel=sigmoid; accuracy: (test=0.952) f1_score: (test=0.915) precision: (test=0.930) recall: (test=0.899) total time=   0.5s\n",
      "[CV 8/10] END C=25, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.922) recall: (test=0.992) total time=   0.5s\n",
      "[CV 9/10] END C=25, kernel=sigmoid; accuracy: (test=0.964) f1_score: (test=0.935) precision: (test=0.964) recall: (test=0.908) total time=   0.5s\n",
      "[CV 10/10] END C=25, kernel=sigmoid; accuracy: (test=0.956) f1_score: (test=0.926) precision: (test=0.911) recall: (test=0.941) total time=   0.5s\n",
      "[CV 1/10] END C=25, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=25, kernel=linear; accuracy: (test=0.964) f1_score: (test=0.938) precision: (test=0.927) recall: (test=0.950) total time=   0.7s\n",
      "[CV 3/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.7s\n",
      "[CV 4/10] END C=25, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.7s\n",
      "[CV 5/10] END C=25, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.915) recall: (test=0.992) total time=   0.7s\n",
      "[CV 6/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.6s\n",
      "[CV 7/10] END C=25, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.7s\n",
      "[CV 8/10] END C=25, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.7s\n",
      "[CV 9/10] END C=25, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.935) recall: (test=0.966) total time=   0.6s\n",
      "[CV 10/10] END C=25, kernel=linear; accuracy: (test=0.969) f1_score: (test=0.947) precision: (test=0.914) recall: (test=0.983) total time=   0.7s\n",
      "[CV 1/10] END C=50, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.801) precision: (test=0.672) recall: (test=0.992) total time=   3.7s\n",
      "[CV 2/10] END C=50, kernel=poly; accuracy: (test=0.896) f1_score: (test=0.846) precision: (test=0.742) recall: (test=0.983) total time=   3.7s\n",
      "[CV 3/10] END C=50, kernel=poly; accuracy: (test=0.884) f1_score: (test=0.831) precision: (test=0.715) recall: (test=0.992) total time=   3.6s\n",
      "[CV 4/10] END C=50, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.801) precision: (test=0.669) recall: (test=1.000) total time=   3.6s\n",
      "[CV 5/10] END C=50, kernel=poly; accuracy: (test=0.882) f1_score: (test=0.829) precision: (test=0.708) recall: (test=1.000) total time=   3.6s\n",
      "[CV 6/10] END C=50, kernel=poly; accuracy: (test=0.884) f1_score: (test=0.832) precision: (test=0.713) recall: (test=1.000) total time=   3.7s\n",
      "[CV 7/10] END C=50, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.803) precision: (test=0.674) recall: (test=0.992) total time=   3.8s\n",
      "[CV 8/10] END C=50, kernel=poly; accuracy: (test=0.877) f1_score: (test=0.824) precision: (test=0.700) recall: (test=1.000) total time=   3.7s\n",
      "[CV 9/10] END C=50, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.805) precision: (test=0.678) recall: (test=0.992) total time=   3.8s\n",
      "[CV 10/10] END C=50, kernel=poly; accuracy: (test=0.850) f1_score: (test=0.793) precision: (test=0.657) recall: (test=1.000) total time=   3.7s\n",
      "[CV 1/10] END C=50, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=50, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.7s\n",
      "[CV 3/10] END C=50, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.7s\n",
      "[CV 4/10] END C=50, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=50, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.6s\n",
      "[CV 6/10] END C=50, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=50, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=50, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.6s\n",
      "[CV 9/10] END C=50, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=50, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=50, kernel=sigmoid; accuracy: (test=0.942) f1_score: (test=0.902) precision: (test=0.881) recall: (test=0.925) total time=   0.5s\n",
      "[CV 2/10] END C=50, kernel=sigmoid; accuracy: (test=0.959) f1_score: (test=0.929) precision: (test=0.926) recall: (test=0.933) total time=   0.5s\n",
      "[CV 3/10] END C=50, kernel=sigmoid; accuracy: (test=0.966) f1_score: (test=0.942) precision: (test=0.934) recall: (test=0.950) total time=   0.4s\n",
      "[CV 4/10] END C=50, kernel=sigmoid; accuracy: (test=0.944) f1_score: (test=0.905) precision: (test=0.887) recall: (test=0.924) total time=   0.4s\n",
      "[CV 5/10] END C=50, kernel=sigmoid; accuracy: (test=0.949) f1_score: (test=0.912) precision: (test=0.908) recall: (test=0.916) total time=   0.4s\n",
      "[CV 6/10] END C=50, kernel=sigmoid; accuracy: (test=0.959) f1_score: (test=0.929) precision: (test=0.918) recall: (test=0.941) total time=   0.4s\n",
      "[CV 7/10] END C=50, kernel=sigmoid; accuracy: (test=0.942) f1_score: (test=0.896) precision: (test=0.928) recall: (test=0.866) total time=   0.4s\n",
      "[CV 8/10] END C=50, kernel=sigmoid; accuracy: (test=0.966) f1_score: (test=0.942) precision: (test=0.927) recall: (test=0.958) total time=   0.4s\n",
      "[CV 9/10] END C=50, kernel=sigmoid; accuracy: (test=0.952) f1_score: (test=0.914) precision: (test=0.938) recall: (test=0.891) total time=   0.4s\n",
      "[CV 10/10] END C=50, kernel=sigmoid; accuracy: (test=0.942) f1_score: (test=0.902) precision: (test=0.874) recall: (test=0.933) total time=   0.5s\n",
      "[CV 1/10] END C=50, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=50, kernel=linear; accuracy: (test=0.964) f1_score: (test=0.938) precision: (test=0.927) recall: (test=0.950) total time=   0.7s\n",
      "[CV 3/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.7s\n",
      "[CV 4/10] END C=50, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.7s\n",
      "[CV 5/10] END C=50, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.915) recall: (test=0.992) total time=   0.7s\n",
      "[CV 6/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.7s\n",
      "[CV 7/10] END C=50, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.6s\n",
      "[CV 8/10] END C=50, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.7s\n",
      "[CV 9/10] END C=50, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.935) recall: (test=0.966) total time=   0.6s\n",
      "[CV 10/10] END C=50, kernel=linear; accuracy: (test=0.969) f1_score: (test=0.947) precision: (test=0.914) recall: (test=0.983) total time=   0.7s\n",
      "[CV 1/10] END C=100, kernel=poly; accuracy: (test=0.763) f1_score: (test=0.710) precision: (test=0.550) recall: (test=1.000) total time=   3.4s\n",
      "[CV 2/10] END C=100, kernel=poly; accuracy: (test=0.819) f1_score: (test=0.760) precision: (test=0.617) recall: (test=0.992) total time=   3.6s\n",
      "[CV 3/10] END C=100, kernel=poly; accuracy: (test=0.775) f1_score: (test=0.717) precision: (test=0.562) recall: (test=0.992) total time=   3.5s\n",
      "[CV 4/10] END C=100, kernel=poly; accuracy: (test=0.768) f1_score: (test=0.713) precision: (test=0.553) recall: (test=1.000) total time=   4.1s\n",
      "[CV 5/10] END C=100, kernel=poly; accuracy: (test=0.800) f1_score: (test=0.741) precision: (test=0.589) recall: (test=1.000) total time=   3.5s\n",
      "[CV 6/10] END C=100, kernel=poly; accuracy: (test=0.804) f1_score: (test=0.746) precision: (test=0.595) recall: (test=1.000) total time=   3.4s\n",
      "[CV 7/10] END C=100, kernel=poly; accuracy: (test=0.778) f1_score: (test=0.720) precision: (test=0.565) recall: (test=0.992) total time=   3.5s\n",
      "[CV 8/10] END C=100, kernel=poly; accuracy: (test=0.782) f1_score: (test=0.726) precision: (test=0.569) recall: (test=1.000) total time=   3.5s\n",
      "[CV 9/10] END C=100, kernel=poly; accuracy: (test=0.772) f1_score: (test=0.715) precision: (test=0.559) recall: (test=0.992) total time=   3.5s\n",
      "[CV 10/10] END C=100, kernel=poly; accuracy: (test=0.768) f1_score: (test=0.713) precision: (test=0.553) recall: (test=1.000) total time=   4.7s\n",
      "[CV 1/10] END C=100, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 2/10] END C=100, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.6s\n",
      "[CV 3/10] END C=100, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.6s\n",
      "[CV 4/10] END C=100, kernel=rbf; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=100, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.7s\n",
      "[CV 6/10] END C=100, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=100, kernel=rbf; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.7s\n",
      "[CV 8/10] END C=100, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   1.7s\n",
      "[CV 9/10] END C=100, kernel=rbf; accuracy: (test=0.969) f1_score: (test=0.946) precision: (test=0.942) recall: (test=0.950) total time=   1.6s\n",
      "[CV 10/10] END C=100, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.7s\n",
      "[CV 1/10] END C=100, kernel=sigmoid; accuracy: (test=0.932) f1_score: (test=0.888) precision: (test=0.854) recall: (test=0.925) total time=   0.4s\n",
      "[CV 2/10] END C=100, kernel=sigmoid; accuracy: (test=0.952) f1_score: (test=0.918) precision: (test=0.903) recall: (test=0.933) total time=   0.5s\n",
      "[CV 3/10] END C=100, kernel=sigmoid; accuracy: (test=0.954) f1_score: (test=0.920) precision: (test=0.924) recall: (test=0.916) total time=   0.4s\n",
      "[CV 4/10] END C=100, kernel=sigmoid; accuracy: (test=0.940) f1_score: (test=0.895) precision: (test=0.898) recall: (test=0.891) total time=   0.4s\n",
      "[CV 5/10] END C=100, kernel=sigmoid; accuracy: (test=0.949) f1_score: (test=0.912) precision: (test=0.908) recall: (test=0.916) total time=   0.4s\n",
      "[CV 6/10] END C=100, kernel=sigmoid; accuracy: (test=0.957) f1_score: (test=0.924) precision: (test=0.932) recall: (test=0.916) total time=   0.4s\n",
      "[CV 7/10] END C=100, kernel=sigmoid; accuracy: (test=0.940) f1_score: (test=0.892) precision: (test=0.920) recall: (test=0.866) total time=   0.4s\n",
      "[CV 8/10] END C=100, kernel=sigmoid; accuracy: (test=0.954) f1_score: (test=0.920) precision: (test=0.924) recall: (test=0.916) total time=   0.4s\n",
      "[CV 9/10] END C=100, kernel=sigmoid; accuracy: (test=0.949) f1_score: (test=0.911) precision: (test=0.922) recall: (test=0.899) total time=   0.5s\n",
      "[CV 10/10] END C=100, kernel=sigmoid; accuracy: (test=0.932) f1_score: (test=0.886) precision: (test=0.858) recall: (test=0.916) total time=   0.4s\n",
      "[CV 1/10] END C=100, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   0.7s\n",
      "[CV 2/10] END C=100, kernel=linear; accuracy: (test=0.964) f1_score: (test=0.938) precision: (test=0.927) recall: (test=0.950) total time=   0.7s\n",
      "[CV 3/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   0.7s\n",
      "[CV 4/10] END C=100, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   0.7s\n",
      "[CV 5/10] END C=100, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.915) recall: (test=0.992) total time=   0.7s\n",
      "[CV 6/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   0.7s\n",
      "[CV 7/10] END C=100, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.950) recall: (test=0.950) total time=   0.7s\n",
      "[CV 8/10] END C=100, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   0.7s\n",
      "[CV 9/10] END C=100, kernel=linear; accuracy: (test=0.971) f1_score: (test=0.950) precision: (test=0.935) recall: (test=0.966) total time=   0.7s\n",
      "[CV 10/10] END C=100, kernel=linear; accuracy: (test=0.969) f1_score: (test=0.947) precision: (test=0.914) recall: (test=0.983) total time=   0.7s\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9958    0.9794    0.9875       727\n",
      "        spam     0.9531    0.9903    0.9713       308\n",
      "\n",
      "    accuracy                         0.9826      1035\n",
      "   macro avg     0.9745    0.9848    0.9794      1035\n",
      "weighted avg     0.9831    0.9826    0.9827      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gridsearch Linear SVM with stemmed data\n",
    "\n",
    "# when using more than 1 score to decide best model, need to specify which score to be used for \"refit\" \n",
    "grid_stem = GridSearchCV(SVC(), param_tuning, refit = 'f1_score', verbose = 3,  scoring = scoring_rule, cv = 10)  \n",
    "\n",
    "# grid search with training data set\n",
    "grid_stem.fit(X_stem_train, y_stem_train)\n",
    "# print the best parameter\n",
    "print(grid_stem.best_params_)\n",
    "\n",
    "# predicting the testing dataset\n",
    "grid_stem_pred = grid_stem.predict(X_stem_test)\n",
    "# print prediction result\n",
    "print(classification_report(y_stem_test, grid_stem_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n",
      "[CV 1/10] END C=1, kernel=poly; accuracy: (test=0.853) f1_score: (test=0.659) precision: (test=1.000) recall: (test=0.492) total time=   5.7s\n",
      "[CV 2/10] END C=1, kernel=poly; accuracy: (test=0.819) f1_score: (test=0.545) precision: (test=1.000) recall: (test=0.375) total time=   5.8s\n",
      "[CV 3/10] END C=1, kernel=poly; accuracy: (test=0.848) f1_score: (test=0.640) precision: (test=1.000) recall: (test=0.471) total time=   5.8s\n",
      "[CV 4/10] END C=1, kernel=poly; accuracy: (test=0.821) f1_score: (test=0.549) precision: (test=1.000) recall: (test=0.378) total time=   5.8s\n",
      "[CV 5/10] END C=1, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.636) precision: (test=0.982) recall: (test=0.471) total time=   5.6s\n",
      "[CV 6/10] END C=1, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.632) precision: (test=1.000) recall: (test=0.462) total time=   5.5s\n",
      "[CV 7/10] END C=1, kernel=poly; accuracy: (test=0.831) f1_score: (test=0.583) precision: (test=1.000) recall: (test=0.412) total time=   5.3s\n",
      "[CV 8/10] END C=1, kernel=poly; accuracy: (test=0.852) f1_score: (test=0.655) precision: (test=1.000) recall: (test=0.487) total time=   6.2s\n",
      "[CV 9/10] END C=1, kernel=poly; accuracy: (test=0.833) f1_score: (test=0.592) precision: (test=1.000) recall: (test=0.420) total time=   5.4s\n",
      "[CV 10/10] END C=1, kernel=poly; accuracy: (test=0.843) f1_score: (test=0.624) precision: (test=1.000) recall: (test=0.454) total time=   5.1s\n",
      "[CV 1/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   3.8s\n",
      "[CV 2/10] END C=1, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   3.8s\n",
      "[CV 3/10] END C=1, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   3.8s\n",
      "[CV 4/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   3.8s\n",
      "[CV 5/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   3.8s\n",
      "[CV 6/10] END C=1, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   3.8s\n",
      "[CV 7/10] END C=1, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   3.9s\n",
      "[CV 8/10] END C=1, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   3.8s\n",
      "[CV 9/10] END C=1, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   3.7s\n",
      "[CV 10/10] END C=1, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   3.7s\n",
      "[CV 1/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.4s\n",
      "[CV 2/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.3s\n",
      "[CV 3/10] END C=1, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   1.4s\n",
      "[CV 4/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.3s\n",
      "[CV 5/10] END C=1, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.4s\n",
      "[CV 6/10] END C=1, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=1, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.3s\n",
      "[CV 8/10] END C=1, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.3s\n",
      "[CV 9/10] END C=1, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.4s\n",
      "[CV 10/10] END C=1, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.4s\n",
      "[CV 1/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.5s\n",
      "[CV 2/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.5s\n",
      "[CV 3/10] END C=1, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   1.4s\n",
      "[CV 4/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.4s\n",
      "[CV 5/10] END C=1, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=1, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.7s\n",
      "[CV 7/10] END C=1, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   1.6s\n",
      "[CV 8/10] END C=1, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.6s\n",
      "[CV 9/10] END C=1, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.5s\n",
      "[CV 10/10] END C=1, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=2, kernel=poly; accuracy: (test=0.867) f1_score: (test=0.703) precision: (test=1.000) recall: (test=0.542) total time=   5.4s\n",
      "[CV 2/10] END C=2, kernel=poly; accuracy: (test=0.833) f1_score: (test=0.596) precision: (test=1.000) recall: (test=0.425) total time=   5.4s\n",
      "[CV 3/10] END C=2, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.5s\n",
      "[CV 4/10] END C=2, kernel=poly; accuracy: (test=0.826) f1_score: (test=0.566) precision: (test=1.000) recall: (test=0.395) total time=   5.5s\n",
      "[CV 5/10] END C=2, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.681) precision: (test=0.984) recall: (test=0.521) total time=   5.6s\n",
      "[CV 6/10] END C=2, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.670) precision: (test=1.000) recall: (test=0.504) total time=   5.2s\n",
      "[CV 7/10] END C=2, kernel=poly; accuracy: (test=0.848) f1_score: (test=0.640) precision: (test=1.000) recall: (test=0.471) total time=   5.3s\n",
      "[CV 8/10] END C=2, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.2s\n",
      "[CV 9/10] END C=2, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   5.3s\n",
      "[CV 10/10] END C=2, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.681) precision: (test=0.984) recall: (test=0.521) total time=   5.3s\n",
      "[CV 1/10] END C=2, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   3.9s\n",
      "[CV 2/10] END C=2, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   3.9s\n",
      "[CV 3/10] END C=2, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   3.9s\n",
      "[CV 4/10] END C=2, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.0s\n",
      "[CV 5/10] END C=2, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   3.9s\n",
      "[CV 6/10] END C=2, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   3.9s\n",
      "[CV 7/10] END C=2, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   3.9s\n",
      "[CV 8/10] END C=2, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   3.9s\n",
      "[CV 9/10] END C=2, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.0s\n",
      "[CV 10/10] END C=2, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.0s\n",
      "[CV 1/10] END C=2, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   1.2s\n",
      "[CV 2/10] END C=2, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.2s\n",
      "[CV 3/10] END C=2, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   1.3s\n",
      "[CV 4/10] END C=2, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.951) recall: (test=0.975) total time=   1.3s\n",
      "[CV 5/10] END C=2, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.960) recall: (test=1.000) total time=   1.4s\n",
      "[CV 6/10] END C=2, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.3s\n",
      "[CV 7/10] END C=2, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.3s\n",
      "[CV 8/10] END C=2, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   1.3s\n",
      "[CV 9/10] END C=2, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.974) recall: (test=0.958) total time=   1.3s\n",
      "[CV 10/10] END C=2, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.3s\n",
      "[CV 1/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.5s\n",
      "[CV 2/10] END C=2, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 3/10] END C=2, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.5s\n",
      "[CV 4/10] END C=2, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   1.4s\n",
      "[CV 5/10] END C=2, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=2, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.5s\n",
      "[CV 7/10] END C=2, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.7s\n",
      "[CV 8/10] END C=2, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.6s\n",
      "[CV 9/10] END C=2, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.966) recall: (test=0.958) total time=   1.6s\n",
      "[CV 10/10] END C=2, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.6s\n",
      "[CV 1/10] END C=5, kernel=poly; accuracy: (test=0.870) f1_score: (test=0.710) precision: (test=1.000) recall: (test=0.550) total time=   5.7s\n",
      "[CV 2/10] END C=5, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.613) precision: (test=1.000) recall: (test=0.442) total time=   5.7s\n",
      "[CV 3/10] END C=5, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.685) precision: (test=1.000) recall: (test=0.521) total time=   6.6s\n",
      "[CV 4/10] END C=5, kernel=poly; accuracy: (test=0.836) f1_score: (test=0.600) precision: (test=1.000) recall: (test=0.429) total time=   5.5s\n",
      "[CV 5/10] END C=5, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.689) precision: (test=0.984) recall: (test=0.529) total time=   5.5s\n",
      "[CV 6/10] END C=5, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.670) precision: (test=1.000) recall: (test=0.504) total time=   5.3s\n",
      "[CV 7/10] END C=5, kernel=poly; accuracy: (test=0.860) f1_score: (test=0.678) precision: (test=1.000) recall: (test=0.513) total time=   5.4s\n",
      "[CV 8/10] END C=5, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.685) precision: (test=1.000) recall: (test=0.521) total time=   5.3s\n",
      "[CV 9/10] END C=5, kernel=poly; accuracy: (test=0.838) f1_score: (test=0.608) precision: (test=1.000) recall: (test=0.437) total time=   6.2s\n",
      "[CV 10/10] END C=5, kernel=poly; accuracy: (test=0.864) f1_score: (test=0.696) precision: (test=0.985) recall: (test=0.538) total time=   7.0s\n",
      "[CV 1/10] END C=5, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.6s\n",
      "[CV 2/10] END C=5, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.8s\n",
      "[CV 3/10] END C=5, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.5s\n",
      "[CV 4/10] END C=5, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.7s\n",
      "[CV 5/10] END C=5, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   5.2s\n",
      "[CV 6/10] END C=5, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   4.4s\n",
      "[CV 7/10] END C=5, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   4.4s\n",
      "[CV 8/10] END C=5, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   4.7s\n",
      "[CV 9/10] END C=5, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.3s\n",
      "[CV 10/10] END C=5, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.3s\n",
      "[CV 1/10] END C=5, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.936) recall: (test=0.975) total time=   1.3s\n",
      "[CV 2/10] END C=5, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   1.3s\n",
      "[CV 3/10] END C=5, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.3s\n",
      "[CV 4/10] END C=5, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.958) recall: (test=0.966) total time=   1.3s\n",
      "[CV 5/10] END C=5, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.951) recall: (test=0.983) total time=   1.3s\n",
      "[CV 6/10] END C=5, kernel=sigmoid; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.992) recall: (test=0.992) total time=   1.5s\n",
      "[CV 7/10] END C=5, kernel=sigmoid; accuracy: (test=0.986) f1_score: (test=0.974) precision: (test=0.991) recall: (test=0.958) total time=   1.3s\n",
      "[CV 8/10] END C=5, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   1.3s\n",
      "[CV 9/10] END C=5, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.962) precision: (test=0.974) recall: (test=0.950) total time=   1.3s\n",
      "[CV 10/10] END C=5, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.4s\n",
      "[CV 1/10] END C=5, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.7s\n",
      "[CV 2/10] END C=5, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 3/10] END C=5, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.975) recall: (test=0.975) total time=   1.6s\n",
      "[CV 4/10] END C=5, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.959) recall: (test=0.975) total time=   1.6s\n",
      "[CV 5/10] END C=5, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.952) recall: (test=1.000) total time=   1.7s\n",
      "[CV 6/10] END C=5, kernel=linear; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=0.992) recall: (test=1.000) total time=   1.6s\n",
      "[CV 7/10] END C=5, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.991) recall: (test=0.966) total time=   1.7s\n",
      "[CV 8/10] END C=5, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.7s\n",
      "[CV 9/10] END C=5, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.958) precision: (test=0.958) recall: (test=0.958) total time=   1.7s\n",
      "[CV 10/10] END C=5, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.6s\n",
      "[CV 1/10] END C=10, kernel=poly; accuracy: (test=0.874) f1_score: (test=0.723) precision: (test=1.000) recall: (test=0.567) total time=   6.4s\n",
      "[CV 2/10] END C=10, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.636) precision: (test=1.000) recall: (test=0.467) total time=   6.2s\n",
      "[CV 3/10] END C=10, kernel=poly; accuracy: (test=0.874) f1_score: (test=0.720) precision: (test=1.000) recall: (test=0.563) total time=   6.1s\n",
      "[CV 4/10] END C=10, kernel=poly; accuracy: (test=0.841) f1_score: (test=0.616) precision: (test=1.000) recall: (test=0.445) total time=   6.2s\n",
      "[CV 5/10] END C=10, kernel=poly; accuracy: (test=0.872) f1_score: (test=0.717) precision: (test=0.985) recall: (test=0.563) total time=   6.3s\n",
      "[CV 6/10] END C=10, kernel=poly; accuracy: (test=0.877) f1_score: (test=0.727) precision: (test=1.000) recall: (test=0.571) total time=   6.2s\n",
      "[CV 7/10] END C=10, kernel=poly; accuracy: (test=0.865) f1_score: (test=0.692) precision: (test=1.000) recall: (test=0.529) total time=   6.3s\n",
      "[CV 8/10] END C=10, kernel=poly; accuracy: (test=0.862) f1_score: (test=0.685) precision: (test=1.000) recall: (test=0.521) total time=   6.3s\n",
      "[CV 9/10] END C=10, kernel=poly; accuracy: (test=0.845) f1_score: (test=0.632) precision: (test=1.000) recall: (test=0.462) total time=   6.2s\n",
      "[CV 10/10] END C=10, kernel=poly; accuracy: (test=0.874) f1_score: (test=0.723) precision: (test=0.986) recall: (test=0.571) total time=   6.3s\n",
      "[CV 1/10] END C=10, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 2/10] END C=10, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.4s\n",
      "[CV 3/10] END C=10, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.4s\n",
      "[CV 4/10] END C=10, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.5s\n",
      "[CV 5/10] END C=10, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   4.5s\n",
      "[CV 6/10] END C=10, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   4.4s\n",
      "[CV 7/10] END C=10, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   4.4s\n",
      "[CV 8/10] END C=10, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   4.4s\n",
      "[CV 9/10] END C=10, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.4s\n",
      "[CV 10/10] END C=10, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.4s\n",
      "[CV 1/10] END C=10, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.937) recall: (test=0.983) total time=   1.3s\n",
      "[CV 2/10] END C=10, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.3s\n",
      "[CV 3/10] END C=10, kernel=sigmoid; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.975) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=10, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.2s\n",
      "[CV 5/10] END C=10, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.3s\n",
      "[CV 6/10] END C=10, kernel=sigmoid; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.3s\n",
      "[CV 7/10] END C=10, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.983) recall: (test=0.958) total time=   1.3s\n",
      "[CV 8/10] END C=10, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.2s\n",
      "[CV 9/10] END C=10, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.958) precision: (test=0.958) recall: (test=0.958) total time=   1.2s\n",
      "[CV 10/10] END C=10, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.2s\n",
      "[CV 1/10] END C=10, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.5s\n",
      "[CV 2/10] END C=10, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.5s\n",
      "[CV 3/10] END C=10, kernel=linear; accuracy: (test=0.993) f1_score: (test=0.987) precision: (test=0.983) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=10, kernel=linear; accuracy: (test=0.986) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.5s\n",
      "[CV 5/10] END C=10, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.944) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=10, kernel=linear; accuracy: (test=0.995) f1_score: (test=0.992) precision: (test=0.983) recall: (test=1.000) total time=   1.5s\n",
      "[CV 7/10] END C=10, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.983) recall: (test=0.975) total time=   1.6s\n",
      "[CV 8/10] END C=10, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.6s\n",
      "[CV 9/10] END C=10, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   1.5s\n",
      "[CV 10/10] END C=10, kernel=linear; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.6s\n",
      "[CV 1/10] END C=25, kernel=poly; accuracy: (test=0.930) f1_score: (test=0.865) precision: (test=0.979) recall: (test=0.775) total time=   6.0s\n",
      "[CV 2/10] END C=25, kernel=poly; accuracy: (test=0.870) f1_score: (test=0.716) precision: (test=0.971) recall: (test=0.567) total time=   5.9s\n",
      "[CV 3/10] END C=25, kernel=poly; accuracy: (test=0.915) f1_score: (test=0.828) precision: (test=1.000) recall: (test=0.706) total time=   6.3s\n",
      "[CV 4/10] END C=25, kernel=poly; accuracy: (test=0.899) f1_score: (test=0.786) precision: (test=1.000) recall: (test=0.647) total time=   6.2s\n",
      "[CV 5/10] END C=25, kernel=poly; accuracy: (test=0.911) f1_score: (test=0.818) precision: (test=0.988) recall: (test=0.697) total time=   7.0s\n",
      "[CV 6/10] END C=25, kernel=poly; accuracy: (test=0.899) f1_score: (test=0.786) precision: (test=1.000) recall: (test=0.647) total time=   6.0s\n",
      "[CV 7/10] END C=25, kernel=poly; accuracy: (test=0.908) f1_score: (test=0.810) precision: (test=1.000) recall: (test=0.681) total time=   6.1s\n",
      "[CV 8/10] END C=25, kernel=poly; accuracy: (test=0.910) f1_score: (test=0.818) precision: (test=0.988) recall: (test=0.697) total time=   6.1s\n",
      "[CV 9/10] END C=25, kernel=poly; accuracy: (test=0.867) f1_score: (test=0.703) precision: (test=0.985) recall: (test=0.546) total time=   6.1s\n",
      "[CV 10/10] END C=25, kernel=poly; accuracy: (test=0.906) f1_score: (test=0.806) precision: (test=0.988) recall: (test=0.681) total time=   6.1s\n",
      "[CV 1/10] END C=25, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 2/10] END C=25, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 3/10] END C=25, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.3s\n",
      "[CV 4/10] END C=25, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.3s\n",
      "[CV 5/10] END C=25, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   4.2s\n",
      "[CV 6/10] END C=25, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   4.2s\n",
      "[CV 7/10] END C=25, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   4.3s\n",
      "[CV 8/10] END C=25, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   4.3s\n",
      "[CV 9/10] END C=25, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.3s\n",
      "[CV 10/10] END C=25, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.1s\n",
      "[CV 1/10] END C=25, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.2s\n",
      "[CV 2/10] END C=25, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.948) precision: (test=0.915) recall: (test=0.983) total time=   1.2s\n",
      "[CV 3/10] END C=25, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=25, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.1s\n",
      "[CV 5/10] END C=25, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.1s\n",
      "[CV 6/10] END C=25, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.1s\n",
      "[CV 7/10] END C=25, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.974) recall: (test=0.958) total time=   1.2s\n",
      "[CV 8/10] END C=25, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.2s\n",
      "[CV 9/10] END C=25, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.954) precision: (test=0.943) recall: (test=0.966) total time=   1.2s\n",
      "[CV 10/10] END C=25, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.2s\n",
      "[CV 1/10] END C=25, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 2/10] END C=25, kernel=linear; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.943) recall: (test=0.967) total time=   1.5s\n",
      "[CV 3/10] END C=25, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=25, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.5s\n",
      "[CV 5/10] END C=25, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=25, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=25, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=25, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.5s\n",
      "[CV 9/10] END C=25, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.5s\n",
      "[CV 10/10] END C=25, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.5s\n",
      "[CV 1/10] END C=50, kernel=poly; accuracy: (test=0.930) f1_score: (test=0.892) precision: (test=0.805) recall: (test=1.000) total time=   6.1s\n",
      "[CV 2/10] END C=50, kernel=poly; accuracy: (test=0.930) f1_score: (test=0.866) precision: (test=0.969) recall: (test=0.783) total time=   6.1s\n",
      "[CV 3/10] END C=50, kernel=poly; accuracy: (test=0.937) f1_score: (test=0.901) precision: (test=0.825) recall: (test=0.992) total time=   6.1s\n",
      "[CV 4/10] END C=50, kernel=poly; accuracy: (test=0.928) f1_score: (test=0.888) precision: (test=0.799) recall: (test=1.000) total time=   6.1s\n",
      "[CV 5/10] END C=50, kernel=poly; accuracy: (test=0.969) f1_score: (test=0.948) precision: (test=0.908) recall: (test=0.992) total time=   5.9s\n",
      "[CV 6/10] END C=50, kernel=poly; accuracy: (test=0.976) f1_score: (test=0.960) precision: (test=0.922) recall: (test=1.000) total time=   5.9s\n",
      "[CV 7/10] END C=50, kernel=poly; accuracy: (test=0.928) f1_score: (test=0.888) precision: (test=0.799) recall: (test=1.000) total time=   6.0s\n",
      "[CV 8/10] END C=50, kernel=poly; accuracy: (test=0.915) f1_score: (test=0.871) precision: (test=0.776) recall: (test=0.992) total time=   6.0s\n",
      "[CV 9/10] END C=50, kernel=poly; accuracy: (test=0.964) f1_score: (test=0.940) precision: (test=0.900) recall: (test=0.983) total time=   5.9s\n",
      "[CV 10/10] END C=50, kernel=poly; accuracy: (test=0.901) f1_score: (test=0.852) precision: (test=0.747) recall: (test=0.992) total time=   6.1s\n",
      "[CV 1/10] END C=50, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 2/10] END C=50, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.3s\n",
      "[CV 3/10] END C=50, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.3s\n",
      "[CV 4/10] END C=50, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.3s\n",
      "[CV 5/10] END C=50, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   4.3s\n",
      "[CV 6/10] END C=50, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   4.3s\n",
      "[CV 7/10] END C=50, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   4.3s\n",
      "[CV 8/10] END C=50, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   4.2s\n",
      "[CV 9/10] END C=50, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.1s\n",
      "[CV 10/10] END C=50, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.1s\n",
      "[CV 1/10] END C=50, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.1s\n",
      "[CV 2/10] END C=50, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.948) precision: (test=0.915) recall: (test=0.983) total time=   1.2s\n",
      "[CV 3/10] END C=50, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.1s\n",
      "[CV 4/10] END C=50, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.1s\n",
      "[CV 5/10] END C=50, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.1s\n",
      "[CV 6/10] END C=50, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.1s\n",
      "[CV 7/10] END C=50, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.974) recall: (test=0.958) total time=   1.2s\n",
      "[CV 8/10] END C=50, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.2s\n",
      "[CV 9/10] END C=50, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.954) precision: (test=0.943) recall: (test=0.966) total time=   1.2s\n",
      "[CV 10/10] END C=50, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.2s\n",
      "[CV 1/10] END C=50, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 2/10] END C=50, kernel=linear; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.943) recall: (test=0.967) total time=   1.5s\n",
      "[CV 3/10] END C=50, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=50, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.4s\n",
      "[CV 5/10] END C=50, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=50, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.4s\n",
      "[CV 7/10] END C=50, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=50, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.5s\n",
      "[CV 9/10] END C=50, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.4s\n",
      "[CV 10/10] END C=50, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.4s\n",
      "[CV 1/10] END C=100, kernel=poly; accuracy: (test=0.766) f1_score: (test=0.712) precision: (test=0.553) recall: (test=1.000) total time=   6.0s\n",
      "[CV 2/10] END C=100, kernel=poly; accuracy: (test=0.857) f1_score: (test=0.803) precision: (test=0.670) recall: (test=1.000) total time=   6.1s\n",
      "[CV 3/10] END C=100, kernel=poly; accuracy: (test=0.763) f1_score: (test=0.708) precision: (test=0.548) recall: (test=1.000) total time=   6.7s\n",
      "[CV 4/10] END C=100, kernel=poly; accuracy: (test=0.766) f1_score: (test=0.710) precision: (test=0.551) recall: (test=1.000) total time=   6.3s\n",
      "[CV 5/10] END C=100, kernel=poly; accuracy: (test=0.812) f1_score: (test=0.753) precision: (test=0.604) recall: (test=1.000) total time=   6.2s\n",
      "[CV 6/10] END C=100, kernel=poly; accuracy: (test=0.819) f1_score: (test=0.760) precision: (test=0.613) recall: (test=1.000) total time=   6.2s\n",
      "[CV 7/10] END C=100, kernel=poly; accuracy: (test=0.775) f1_score: (test=0.719) precision: (test=0.561) recall: (test=1.000) total time=   6.2s\n",
      "[CV 8/10] END C=100, kernel=poly; accuracy: (test=0.797) f1_score: (test=0.739) precision: (test=0.586) recall: (test=1.000) total time=   6.3s\n",
      "[CV 9/10] END C=100, kernel=poly; accuracy: (test=0.792) f1_score: (test=0.733) precision: (test=0.581) recall: (test=0.992) total time=   6.3s\n",
      "[CV 10/10] END C=100, kernel=poly; accuracy: (test=0.758) f1_score: (test=0.704) precision: (test=0.543) recall: (test=1.000) total time=   6.3s\n",
      "[CV 1/10] END C=100, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.5s\n",
      "[CV 2/10] END C=100, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.952) recall: (test=0.983) total time=   4.4s\n",
      "[CV 3/10] END C=100, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.983) recall: (test=0.983) total time=   4.4s\n",
      "[CV 4/10] END C=100, kernel=rbf; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   4.3s\n",
      "[CV 5/10] END C=100, kernel=rbf; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   4.4s\n",
      "[CV 6/10] END C=100, kernel=rbf; accuracy: (test=0.998) f1_score: (test=0.996) precision: (test=1.000) recall: (test=0.992) total time=   4.5s\n",
      "[CV 7/10] END C=100, kernel=rbf; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=1.000) recall: (test=0.966) total time=   4.5s\n",
      "[CV 8/10] END C=100, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.967) recall: (test=0.983) total time=   4.6s\n",
      "[CV 9/10] END C=100, kernel=rbf; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.966) recall: (test=0.966) total time=   4.6s\n",
      "[CV 10/10] END C=100, kernel=rbf; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.983) recall: (test=0.966) total time=   4.5s\n",
      "[CV 1/10] END C=100, kernel=sigmoid; accuracy: (test=0.971) f1_score: (test=0.952) precision: (test=0.922) recall: (test=0.983) total time=   1.2s\n",
      "[CV 2/10] END C=100, kernel=sigmoid; accuracy: (test=0.969) f1_score: (test=0.948) precision: (test=0.915) recall: (test=0.983) total time=   1.2s\n",
      "[CV 3/10] END C=100, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.959) recall: (test=0.983) total time=   1.2s\n",
      "[CV 4/10] END C=100, kernel=sigmoid; accuracy: (test=0.983) f1_score: (test=0.970) precision: (test=0.975) recall: (test=0.966) total time=   1.2s\n",
      "[CV 5/10] END C=100, kernel=sigmoid; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.936) recall: (test=0.983) total time=   1.3s\n",
      "[CV 6/10] END C=100, kernel=sigmoid; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.2s\n",
      "[CV 7/10] END C=100, kernel=sigmoid; accuracy: (test=0.981) f1_score: (test=0.966) precision: (test=0.974) recall: (test=0.958) total time=   1.2s\n",
      "[CV 8/10] END C=100, kernel=sigmoid; accuracy: (test=0.985) f1_score: (test=0.975) precision: (test=0.959) recall: (test=0.992) total time=   1.2s\n",
      "[CV 9/10] END C=100, kernel=sigmoid; accuracy: (test=0.973) f1_score: (test=0.954) precision: (test=0.943) recall: (test=0.966) total time=   1.2s\n",
      "[CV 10/10] END C=100, kernel=sigmoid; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.937) recall: (test=0.992) total time=   1.2s\n",
      "[CV 1/10] END C=100, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.963) precision: (test=0.944) recall: (test=0.983) total time=   1.5s\n",
      "[CV 2/10] END C=100, kernel=linear; accuracy: (test=0.973) f1_score: (test=0.955) precision: (test=0.943) recall: (test=0.967) total time=   1.5s\n",
      "[CV 3/10] END C=100, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.975) recall: (test=0.992) total time=   1.5s\n",
      "[CV 4/10] END C=100, kernel=linear; accuracy: (test=0.990) f1_score: (test=0.983) precision: (test=0.967) recall: (test=1.000) total time=   1.5s\n",
      "[CV 5/10] END C=100, kernel=linear; accuracy: (test=0.978) f1_score: (test=0.964) precision: (test=0.930) recall: (test=1.000) total time=   1.5s\n",
      "[CV 6/10] END C=100, kernel=linear; accuracy: (test=0.988) f1_score: (test=0.979) precision: (test=0.967) recall: (test=0.992) total time=   1.5s\n",
      "[CV 7/10] END C=100, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.967) recall: (test=0.975) total time=   1.5s\n",
      "[CV 8/10] END C=100, kernel=linear; accuracy: (test=0.981) f1_score: (test=0.967) precision: (test=0.937) recall: (test=1.000) total time=   1.5s\n",
      "[CV 9/10] END C=100, kernel=linear; accuracy: (test=0.976) f1_score: (test=0.959) precision: (test=0.943) recall: (test=0.975) total time=   1.5s\n",
      "[CV 10/10] END C=100, kernel=linear; accuracy: (test=0.983) f1_score: (test=0.971) precision: (test=0.952) recall: (test=0.992) total time=   1.5s\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9931    0.9876    0.9903       727\n",
      "        spam     0.9712    0.9838    0.9774       308\n",
      "\n",
      "    accuracy                         0.9865      1035\n",
      "   macro avg     0.9821    0.9857    0.9839      1035\n",
      "weighted avg     0.9866    0.9865    0.9865      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gridsearch Linear SVM with lemmatized data\n",
    "\n",
    "# when using more than 1 score to decide best model, need to specify which score to be used for \"refit\" \n",
    "grid_lemma =GridSearchCV(SVC(), param_tuning, refit = 'f1_score', verbose = 3,  scoring = scoring_rule, cv = 10) \n",
    "\n",
    "# grid search with training data set\n",
    "grid_lemma.fit(X_lemma_train, y_lemma_train)\n",
    "# print the best parameter\n",
    "print(grid_lemma.best_params_)\n",
    "\n",
    "# predicting the testing dataset\n",
    "grid_lemma_pred = grid_lemma.predict(X_lemma_test)\n",
    "# print prediction result\n",
    "print(classification_report(y_lemma_test, grid_lemma_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
